{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import re\n","import random\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import nltk\n","\n","tf.keras.utils.set_random_seed(1234)\n","\n","MAX_SENTENCE_LEN = 40\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:25:21.031915Z","iopub.execute_input":"2023-08-11T03:25:21.032864Z","iopub.status.idle":"2023-08-11T03:26:05.003552Z","shell.execute_reply.started":"2023-08-11T03:25:21.032822Z","shell.execute_reply":"2023-08-11T03:26:05.002558Z"},"trusted":true,"id":"gN_XIwXmxasx","outputId":"1a39f12d-fb45-4551-e0ca-bb419827019f"},"execution_count":null,"outputs":[{"name":"stderr","text":"D0811 03:25:52.576332278      15 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0811 03:25:52.576355352      15 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0811 03:25:52.576358335      15 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0811 03:25:52.576360858      15 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0811 03:25:52.576363215      15 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0811 03:25:52.576366471      15 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0811 03:25:52.576368940      15 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0811 03:25:52.576371269      15 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0811 03:25:52.576373516      15 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0811 03:25:52.576375732      15 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0811 03:25:52.576377925      15 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0811 03:25:52.576380332      15 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0811 03:25:52.576382570      15 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0811 03:25:52.576384753      15 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0811 03:25:52.576583504      15 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD0811 03:25:52.582089455      15 ev_posix.cc:144]                      Using polling engine: epoll1\nD0811 03:25:52.582111957      15 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0811 03:25:52.582587699      15 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0811 03:25:52.582600102      15 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0811 03:25:52.582603860      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0811 03:25:52.582607524      15 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0811 03:25:52.582610826      15 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0811 03:25:52.582614431      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0811 03:25:52.582621847      15 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0811 03:25:52.582638473      15 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0811 03:25:52.582667373      15 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0811 03:25:52.582682481      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0811 03:25:52.582686569      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0811 03:25:52.582690314      15 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0811 03:25:52.582697250      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0811 03:25:52.582700631      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0811 03:25:52.582704247      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0811 03:25:52.582708674      15 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0811 03:25:52.585236538      15 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0811 03:25:52.597874369     251 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0811 03:25:52.605304958     251 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-08-11T03:25:52.605290555+00:00\"}\n/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":["def clean_text(text):\n","\n","    # remove unnecessary characters in sentences and v\n","\n","    text = text.lower().strip()\n","    #Seperate ?.!, with spaces\n","    text = re.sub(r\"([?.!,])\", r\" \\1 \", text)\n","    #Replace extra spaces with a single space\n","    text = re.sub(r'[\" \"]+', \" \", text)\n","\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"what is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"there's\", \"there is\", text)\n","    text = re.sub(r\"how's\", \"how is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'ve\", \" have\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"n'\", \"ng\", text)\n","    text = re.sub(r\"'bout\", \"about\", text)\n","    text = re.sub(r\"'til\", \"until\", text)\n","    text = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", text)\n","\n","    #Remove trailing spaces\n","    text = text.strip()\n","\n","    return text"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.005707Z","iopub.execute_input":"2023-08-11T03:26:05.006210Z","iopub.status.idle":"2023-08-11T03:26:05.023962Z","shell.execute_reply.started":"2023-08-11T03:26:05.006182Z","shell.execute_reply":"2023-08-11T03:26:05.023107Z"},"trusted":true,"id":"Xn37EgiJxas6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(movie_lines, movie_convs, split_ratio, start_tok, end_tok, subword=False):\n","    #map line ids to line/dialog\n","    conv_map = {}\n","    for line in movie_lines:\n","        if len(line) != 0:\n","            line_split = line.split(\" +++$+++ \")\n","            conv_map[line_split[0]] = line_split[4]\n","\n","    #create list containing lists of conversations\n","    convid_list = []\n","    for line in movie_convs:\n","        if len(line) != 0:\n","            conv = line.split(\" +++$+++ \")[-1][1:-1].strip(\"'\").split(\"', '\")\n","            convid_list.append(conv)\n","\n","    #split into questions and answers\n","    input, response  = [], []\n","\n","    for conv in convid_list:\n","        for i in range(len(conv)-1):\n","            input.append(clean_text(conv_map[conv[i]]))\n","            response.append(clean_text(conv_map[conv[i+1]]))\n","\n","    #Segregating sentences which habe less than or eqqual to 100 words for faster training\n","    filtered_input, filtered_response = [], []\n","\n","    num_qnans_pairs = len(input)\n","\n","    if not subword:\n","        for i in range(num_qnans_pairs):\n","            if len(input[i].split()) <= MAX_SENTENCE_LEN-2 and len(response[i].split()) <= MAX_SENTENCE_LEN-2:\n","                    filtered_input.append(start_tok + \" \" + input[i] + \" \" + end_tok)\n","                    filtered_response.append(start_tok + \" \" + response[i] + \" \" + end_tok)\n","    else:\n","        for i in range(num_qnans_pairs):\n","            if len(input[i].split()) <= MAX_SENTENCE_LEN-2 and len(response[i].split()) <= MAX_SENTENCE_LEN-2:\n","                    filtered_input.append(input[i])\n","                    filtered_response.append(response[i])\n","\n","\n","    #Split to training and test set\n","    training_size = int(len(filtered_input) * split_ratio)\n","\n","    #Shuffe the qn answer pairs\n","    idx = np.arange(len(filtered_input))\n","    random.shuffle(idx)\n","\n","    shuffled_input, shuffled_response = [], []\n","\n","    for i in idx:\n","        shuffled_input.append(filtered_input[i])\n","        shuffled_response.append(filtered_response[i])\n","\n","    train_input, train_responses = shuffled_input[:training_size], shuffled_response[:training_size]\n","    test_input, test_responses = shuffled_input[training_size:], shuffled_response[training_size:]\n","\n","    return (train_input, train_responses), (test_input, test_responses)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.025095Z","iopub.execute_input":"2023-08-11T03:26:05.025391Z","iopub.status.idle":"2023-08-11T03:26:05.044226Z","shell.execute_reply.started":"2023-08-11T03:26:05.025364Z","shell.execute_reply":"2023-08-11T03:26:05.043313Z"},"trusted":true,"id":"TvGn2Tk_xas9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize(train_inputs, train_outputs, test_inputs, test_outputs, oov_tok, num_words):\n","    if num_words is not None:\n","        tokenizer = Tokenizer(num_words=num_words, oov_token=oov_tok, lower=False, filters='\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n',)\n","    else:\n","        tokenizer = Tokenizer(oov_token=oov_tok, lower=False)\n","\n","    tokenizer.fit_on_texts(train_inputs+train_outputs)\n","\n","    train_input_seq = tokenizer.texts_to_sequences(train_inputs)\n","    train_output_seq = tokenizer.texts_to_sequences(train_outputs)\n","\n","    test_input_seq = tokenizer.texts_to_sequences(test_inputs)\n","    test_output_seq = tokenizer.texts_to_sequences(test_outputs)\n","\n","    train_input_seq_pad = pad_sequences(train_input_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    train_output_seq_pad = pad_sequences(train_output_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    test_input_seq_pad = pad_sequences(test_input_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    test_output_seq_pad = pad_sequences(test_output_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    return (train_input_seq_pad, train_output_seq_pad), (test_input_seq_pad, test_output_seq_pad), tokenizer"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.045382Z","iopub.execute_input":"2023-08-11T03:26:05.045678Z","iopub.status.idle":"2023-08-11T03:26:05.060293Z","shell.execute_reply.started":"2023-08-11T03:26:05.045654Z","shell.execute_reply":"2023-08-11T03:26:05.059430Z"},"trusted":true,"id":"r7RA0rtexatA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sub_tokenize(train_inputs, train_outputs, test_inputs, test_outputs, oov_tok, num_words):\n","    # Build tokenizer using tfds for both questions and answers\n","    tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","        train_inputs+train_outputs, target_vocab_size=num_words)\n","\n","    # Define start and end token to indicate the start and end of a sentence\n","    START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","    train_in, train_out, test_in, test_out = [], [], [], []\n","    for i in range(len(train_inputs)):\n","        train_in.append(START_TOKEN + tokenizer.encode(train_inputs[i]) + END_TOKEN)\n","        train_out.append(START_TOKEN + tokenizer.encode(train_outputs[i]) + END_TOKEN)\n","\n","    for i in range(len(test_inputs)):\n","        test_in.append(START_TOKEN + tokenizer.encode(test_inputs[i]) + END_TOKEN)\n","        test_out.append(START_TOKEN + tokenizer.encode(test_outputs[i]) + END_TOKEN)\n","\n","\n","    pad_train_inputs = pad_sequences(train_in, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    pad_train_outputs = pad_sequences(train_out, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    pad_test_inputs = pad_sequences(test_in, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    pad_test_outputs = pad_sequences(test_out, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    return (pad_train_inputs, pad_train_outputs), (pad_test_inputs, pad_test_outputs), tokenizer"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.062762Z","iopub.execute_input":"2023-08-11T03:26:05.063125Z","iopub.status.idle":"2023-08-11T03:26:05.075527Z","shell.execute_reply.started":"2023-08-11T03:26:05.063101Z","shell.execute_reply":"2023-08-11T03:26:05.074654Z"},"trusted":true,"id":"njp3iR3UxatC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_dataset(train_in, train_out, batch_size):\n","    #END token removed from decoder (as there's nothing to predict after the token) input and START token removed from output\n","    dataset = tf.data.Dataset.from_tensor_slices(({\"encoder_in\":train_in, \"decoder_in\":train_out[:,:-1]}, {\"outputs\": train_out[:, 1:]}))\n","    dataset = dataset.cache()\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.076450Z","iopub.execute_input":"2023-08-11T03:26:05.076710Z","iopub.status.idle":"2023-08-11T03:26:05.090155Z","shell.execute_reply.started":"2023-08-11T03:26:05.076688Z","shell.execute_reply":"2023-08-11T03:26:05.089416Z"},"trusted":true,"id":"IC66sL3QxatD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_pad_mask(input):\n","\n","    pad_mask = tf.cast(tf.math.equal(input, 0), tf.float32)\n","    pad_mask = tf.expand_dims(tf.expand_dims(pad_mask, axis=1), axis=1)\n","    return pad_mask\n","\n","def create_look_ahead_mask(input):\n","\n","    seq_len = tf.shape(input)[1]\n","    pad_mask = create_pad_mask(input)\n","\n","    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","    pad_and_look_ahead_mask = tf.maximum(pad_mask, look_ahead_mask)\n","    return pad_and_look_ahead_mask\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.091096Z","iopub.execute_input":"2023-08-11T03:26:05.091351Z","iopub.status.idle":"2023-08-11T03:26:05.101953Z","shell.execute_reply.started":"2023-08-11T03:26:05.091328Z","shell.execute_reply":"2023-08-11T03:26:05.101202Z"},"trusted":true,"id":"Gr55Ss9qxatE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class multiHeadAttn_layer(tf.keras.layers.Layer):\n","    def __init__(self, num_heads, embedding_dim, **kwargs):\n","        #check if nembedding dim divisible by mum_heads\n","        assert embedding_dim%num_heads == 0\n","\n","        super(multiHeadAttn_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.embedding_dim_per_head = self.embedding_dim // self.num_heads\n","\n","        self.query_transform = tf.keras.layers.Dense(self.embedding_dim)\n","        self.key_transform = tf.keras.layers.Dense(self.embedding_dim)\n","        self.value_transform = tf.keras.layers.Dense(self.embedding_dim)\n","\n","        self.permute = tf.keras.layers.Permute((2, 1, 3))\n","        self.dense = tf.keras.layers.Dense(self.embedding_dim)\n","\n","\n","    def get_config(self):\n","        config = super(multiHeadAttn_layer, self).get_config()\n","\n","        #Update config with new layer attributes to make loading models easier\n","        config.update({\"num_heads\": self.num_heads, \"embedding_dim\": self.embedding_dim})\n","\n","        return config\n","\n","    def call(self, query, key, value, mask):\n","\n","        batch_size, q_seq_len, k_seq_len= tf.shape(query)[0], tf.shape(query)[1], tf.shape(key)[1]\n","\n","        #Transform key, query, value\n","        query_transformed = self.query_transform(query)\n","        key_transformed = self.key_transform(key)\n","        value_transformed = self.value_transform(value)\n","\n","        #Reshape  and permute dimensions to perform dot product per head\n","        query_per_head = tf.reshape(query_transformed, (batch_size, q_seq_len, self.num_heads, self.embedding_dim_per_head))\n","        key_per_head = tf.reshape(key_transformed, (batch_size, k_seq_len, self.num_heads, self.embedding_dim_per_head))\n","        value_per_head = tf.reshape(value_transformed, (batch_size, k_seq_len, self.num_heads, self.embedding_dim_per_head))\n","\n","        query_per_head = self.permute(query_per_head)\n","        key_per_head = self.permute(key_per_head)\n","        value_per_head = self.permute(value_per_head)\n","\n","        query_per_head = tf.reshape(query_per_head, (batch_size*self.num_heads, q_seq_len, self.embedding_dim_per_head))\n","        key_per_head = tf.reshape(key_per_head, (batch_size*self.num_heads, k_seq_len, self.embedding_dim_per_head))\n","        value_per_head = tf.reshape(value_per_head, (batch_size*self.num_heads, k_seq_len, self.embedding_dim_per_head))\n","\n","        #Dot product between key and query to find similarities\n","        dot_prod = tf.matmul(query_per_head, key_per_head, transpose_b=True)/ tf.math.sqrt(tf.cast(self.embedding_dim_per_head, dtype=tf.float32))\n","\n","        #To avoid considering the padded tokens and future tokens\n","        dot_prod_reshaped = tf.reshape(dot_prod, (batch_size, self.num_heads, q_seq_len, k_seq_len))\n","\n","        dot_prod_reshaped += mask * -1e9\n","\n","        dot_prod = tf.reshape(dot_prod_reshaped, (batch_size*self.num_heads, q_seq_len, k_seq_len))\n","\n","        #Findding attention weights\n","        attn_weights = tf.nn.softmax(dot_prod, axis=-1)\n","\n","        attn_out = tf.matmul(attn_weights, value_per_head)\n","\n","        #Reshaping the output back to the original shape\n","        attn_out_reshaped = tf.reshape(attn_out, (batch_size, self.num_heads, q_seq_len, self.embedding_dim_per_head))\n","\n","        attn_out_permuted = self.permute(attn_out_reshaped)\n","\n","        attn_out = tf.reshape(attn_out_permuted, (batch_size, q_seq_len, self.embedding_dim))\n","\n","        #Final linear dense layer\n","        output = self.dense(attn_out)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.103016Z","iopub.execute_input":"2023-08-11T03:26:05.103286Z","iopub.status.idle":"2023-08-11T03:26:05.139004Z","shell.execute_reply.started":"2023-08-11T03:26:05.103264Z","shell.execute_reply":"2023-08-11T03:26:05.138125Z"},"trusted":true,"id":"htz72_AYxatF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, max_len=10000, **kwargs):\n","        super(PositionalEncoding_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.max_len = max_len\n","\n","\n","    def get_config(self):\n","        config = super(PositionalEncoding_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"max_len\": self.max_len})\n","\n","        return config\n","\n","    def call(self, input):\n","        batch_size = tf.shape(input)[0]\n","        seq_len = tf.shape(input)[1]\n","\n","        #denominator\n","        den = self.max_len**(tf.range(self.embedding_dim, delta=2, dtype=tf.float32)/self.embedding_dim)\n","        den_stacked = tf.expand_dims(tf.expand_dims(den, axis=0), axis=1)\n","        den_stacked = tf.repeat(tf.repeat(den_stacked, repeats=seq_len, axis=1), repeats=batch_size, axis=0)\n","\n","        #numerator\n","        num_stacked = tf.expand_dims(tf.expand_dims(tf.range(seq_len, dtype=tf.float32), axis=0), axis=2)\n","        num_stacked = tf.repeat(num_stacked, repeats=batch_size, axis=0)\n","\n","        inner_term = num_stacked / den_stacked\n","\n","        postn_encoding = tf.stack([tf.sin(inner_term), tf.cos(inner_term)], axis=-1)\n","\n","        postn_encoding = tf.reshape(postn_encoding, (batch_size, seq_len, self.embedding_dim))\n","\n","        output = input + postn_encoding\n","\n","        # return postn_encoding\n","        return output, postn_encoding\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.140173Z","iopub.execute_input":"2023-08-11T03:26:05.140473Z","iopub.status.idle":"2023-08-11T03:26:05.163916Z","shell.execute_reply.started":"2023-08-11T03:26:05.140447Z","shell.execute_reply":"2023-08-11T03:26:05.163098Z"},"trusted":true,"id":"dC54v771xatG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def postn_encoding_check():\n","\n","    input = tf.ones((2, 10, 64))\n","    _, out = PositionalEncoding_layer(64)(input)\n","\n","    plt.pcolormesh(out[0])\n","    plt.xlabel(\"Depth\")\n","    plt.xlim((0, 64))\n","    plt.ylabel(\"Position\")\n","    plt.colorbar()\n","    plt.show()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.165053Z","iopub.execute_input":"2023-08-11T03:26:05.165370Z","iopub.status.idle":"2023-08-11T03:26:05.187318Z","shell.execute_reply.started":"2023-08-11T03:26:05.165344Z","shell.execute_reply":"2023-08-11T03:26:05.186478Z"},"trusted":true,"id":"AfHiucldxatI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class feed_forward_network(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_units, **kwargs):\n","        super(feed_forward_network, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_units = num_units\n","\n","        self.dense1 = tf.keras.layers.Dense(self.num_units, activation=tf.nn.relu)\n","        self.dense2 = tf.keras.layers.Dense(self.embedding_dim)\n","\n","    def get_config(self):\n","        config = super(feed_forward_network, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_units\": self.num_units})\n","        return config\n","\n","\n","    def call(self, input):\n","        dense_out1 = self.dense1(input)\n","        dense_out2 = self.dense2(dense_out1)\n","        return dense_out2"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.188408Z","iopub.execute_input":"2023-08-11T03:26:05.188708Z","iopub.status.idle":"2023-08-11T03:26:05.206261Z","shell.execute_reply.started":"2023-08-11T03:26:05.188684Z","shell.execute_reply":"2023-08-11T03:26:05.205459Z"},"trusted":true,"id":"zBDpOTo7xatJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class encoder_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(encoder_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.multiheadAttn = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","        self.feed_forward = feed_forward_network(self.embedding_dim, self.num_dense_units)\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","        self.add = tf.keras.layers.Add()\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(encoder_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","        return config\n","\n","    def call(self, input, mask):\n","\n","        attn_out = self.multiheadAttn(input, input, input, mask)\n","        dropout_out1 = self.dropout(attn_out)\n","        res_out1 = self.add([input, dropout_out1])\n","        norm_out1 = self.layernorm(res_out1)\n","\n","        feed_forward_out = self.feed_forward(norm_out1)\n","        dropout_out2 = self.dropout(feed_forward_out)\n","        res_out2 = self.add([norm_out1, dropout_out2])\n","        norm_out2 = self.layernorm(res_out2)\n","\n","        return norm_out2\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.207279Z","iopub.execute_input":"2023-08-11T03:26:05.207561Z","iopub.status.idle":"2023-08-11T03:26:05.227723Z","shell.execute_reply.started":"2023-08-11T03:26:05.207536Z","shell.execute_reply":"2023-08-11T03:26:05.226979Z"},"trusted":true,"id":"oSkidgnKxatJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_encoding_layers, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(Encoder, self).__init__(**kwargs)\n","        self.num_encoding_layers =  num_encoding_layers\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.encoder_layers_list = [encoder_layer(self.embedding_dim, self.num_heads, self.num_dense_units, self.dropout_rate) for _ in range(self.num_encoding_layers)]\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(Encoder, self).get_config()\n","        config.update({\"num_encoding_layers\": self.num_encoding_layers, \"embedding_dim\": self.embedding_dim,\\\n","                       \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, mask):\n","\n","        x = input\n","        for layer in self.encoder_layers_list:\n","            x = layer(x, mask)\n","        output = self.layernorm(x)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.228757Z","iopub.execute_input":"2023-08-11T03:26:05.229028Z","iopub.status.idle":"2023-08-11T03:26:05.243802Z","shell.execute_reply.started":"2023-08-11T03:26:05.229004Z","shell.execute_reply":"2023-08-11T03:26:05.242893Z"},"trusted":true,"id":"H5EyKafbxatK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class decoder_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(decoder_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.multiHeadAttn_self = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","        self.multiHeadAttn_cross = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","\n","        self.feed_forward = feed_forward_network(self.embedding_dim, self.num_dense_units)\n","\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","        self.add = tf.keras.layers.Add()\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","\n","    def get_config(self):\n","        config = super(decoder_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, encoder_output, look_ahead_mask, pad_mask):\n","\n","        self_attn_out = self.multiHeadAttn_self(input, input, input, look_ahead_mask)\n","        dropout_out1 = self.dropout(self_attn_out)\n","        res_out1 = self.add([input, dropout_out1])\n","        norm_out1 = self.layernorm(res_out1)\n","\n","        cross_attn_out = self.multiHeadAttn_cross(norm_out1, encoder_output, encoder_output, pad_mask)\n","        dropout_out2 = self.dropout(cross_attn_out)\n","        res_out2 = self.add([norm_out1, dropout_out2])\n","        norm_out2 = self.layernorm(res_out2)\n","\n","        feed_forward_out = self.feed_forward(norm_out2)\n","        dropout_out3 = self.dropout(feed_forward_out)\n","        res_out3 = self.add([norm_out2, dropout_out3])\n","        norm_out3 = self.layernorm(res_out3)\n","\n","        return norm_out3\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.248790Z","iopub.execute_input":"2023-08-11T03:26:05.249203Z","iopub.status.idle":"2023-08-11T03:26:05.264174Z","shell.execute_reply.started":"2023-08-11T03:26:05.249175Z","shell.execute_reply":"2023-08-11T03:26:05.263313Z"},"trusted":true,"id":"SJm6EP2TxatK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_decoding_layers, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(Decoder, self).__init__(**kwargs)\n","        self.num_decoding_layers =  num_decoding_layers\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.decoder_layers_list = [decoder_layer(self.embedding_dim, self.num_heads, self.num_dense_units, self.dropout_rate) for _ in range(self.num_decoding_layers)]\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(Decoder, self).get_config()\n","        config.update({\"num_decoding_layers\": self.num_decoding_layers, \"embedding_dim\": self.embedding_dim,\\\n","                       \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, encoder_output, look_ahead_mask, pad_mask):\n","\n","        x = input\n","        for layer in self.decoder_layers_list:\n","            x = layer(x, encoder_output, look_ahead_mask, pad_mask)\n","        output = self.layernorm(x)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.265285Z","iopub.execute_input":"2023-08-11T03:26:05.265693Z","iopub.status.idle":"2023-08-11T03:26:05.281289Z","shell.execute_reply.started":"2023-08-11T03:26:05.265666Z","shell.execute_reply":"2023-08-11T03:26:05.280477Z"},"trusted":true,"id":"sd2Kcs2YxatL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Transformer(vocab_size, embedding_dim, num_layers, num_heads, num_dense_units, dropout_rate):\n","\n","    #Tokenized encoder and decoder inputs\n","    encoder_inputs = tf.keras.Input(shape=(None,), name=\"encoder_in\")\n","    decoder_inputs = tf.keras.Input(shape=(None,), name=\"decoder_in\")\n","\n","    #Create masks\n","    encoder_pad_mask = tf.keras.layers.Lambda(create_pad_mask, output_shape=(1, 1, None))(encoder_inputs)\n","    decoder_pad_mask = tf.keras.layers.Lambda(create_pad_mask, output_shape=(1, 1, None))(encoder_inputs)\n","    decoder_look_ahead_mask=  tf.keras.layers.Lambda(create_look_ahead_mask, output_shape=(1, None, None))(decoder_inputs)\n","\n","    #Embed the inputs\n","    embed_encoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim)(encoder_inputs)\n","    embed_decoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim)(decoder_inputs)\n","\n","    #Positional Encoding\n","    encoder_inputs_postn_encoded, _ = PositionalEncoding_layer(embedding_dim)(embed_encoder_inputs)\n","    decoder_inputs_postn_encoded, _ = PositionalEncoding_layer(embedding_dim)(embed_decoder_inputs)\n","\n","    #Encoder\n","    encoder_outputs = Encoder(num_layers, embedding_dim, num_heads, num_dense_units, dropout_rate)(encoder_inputs_postn_encoded, encoder_pad_mask)\n","\n","    #Decoder\n","    decoder_outputs = Decoder(num_layers, embedding_dim, num_heads, num_dense_units, dropout_rate)(decoder_inputs_postn_encoded, encoder_outputs,\\\n","                                                                                                   decoder_look_ahead_mask, decoder_pad_mask)\n","\n","    #Linear layer\n","    logits = tf.keras.layers.Dense(vocab_size, name=\"outputs\")(decoder_outputs)\n","\n","    return tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=logits)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.282327Z","iopub.execute_input":"2023-08-11T03:26:05.282596Z","iopub.status.idle":"2023-08-11T03:26:05.298443Z","shell.execute_reply.started":"2023-08-11T03:26:05.282572Z","shell.execute_reply":"2023-08-11T03:26:05.297641Z"},"trusted":true,"id":"NBLcLsj9xatL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loss_function(y_true, y_pred):\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LEN - 1))\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")(y_true, y_pred)\n","\n","    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","    loss = tf.multiply(loss, mask)\n","\n","    return tf.reduce_mean(loss)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.299489Z","iopub.execute_input":"2023-08-11T03:26:05.299788Z","iopub.status.idle":"2023-08-11T03:26:05.311317Z","shell.execute_reply.started":"2023-08-11T03:26:05.299762Z","shell.execute_reply":"2023-08-11T03:26:05.310586Z"},"trusted":true,"id":"da7_UwoBxatM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LEN - 1))\n","\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.312267Z","iopub.execute_input":"2023-08-11T03:26:05.312520Z","iopub.status.idle":"2023-08-11T03:26:05.325732Z","shell.execute_reply.started":"2023-08-11T03:26:05.312498Z","shell.execute_reply":"2023-08-11T03:26:05.324896Z"},"trusted":true,"id":"JzWbDLPixatM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, embedding_dim, warmup_steps=1000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.embedding_dim = tf.constant(embedding_dim, dtype=tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def get_config(self):\n","        return {\"d_model\": self.d_model, \"warmup_steps\": self.warmup_steps}\n","\n","    def __call__(self, step):\n","        step = tf.cast(step, dtype=tf.float32)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps**-1.5)\n","\n","        lr = tf.math.multiply(tf.math.rsqrt(self.embedding_dim), tf.math.minimum(arg1, arg2))\n","\n","        return lr"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.326688Z","iopub.execute_input":"2023-08-11T03:26:05.326944Z","iopub.status.idle":"2023-08-11T03:26:05.335100Z","shell.execute_reply.started":"2023-08-11T03:26:05.326922Z","shell.execute_reply":"2023-08-11T03:26:05.334266Z"},"trusted":true,"id":"wS4E7igSxatM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction(input, query_sentences, tokenizer, start_token, end_token, model, output=None):\n","\n","    num_inputs = input.shape[0]\n","\n","    bleu_list = []\n","    prediction_list = []\n","    for _ in range(num_inputs):\n","        prediction_list.append([start_token])\n","\n","    prediction_tensor = tf.convert_to_tensor(prediction_list, dtype=tf.int32)\n","\n","    input = tf.convert_to_tensor(input, dtype=tf.int32)\n","\n","    for i in range(MAX_SENTENCE_LEN):\n","        model_out = model.predict([input, prediction_tensor], verbose=0)\n","\n","        last_words = model_out[:, -1:, :]\n","        predicted_id = tf.cast(tf.argmax(last_words, axis=-1), tf.int32)\n","\n","        # concatenated the predicted_id to the output which is given to the decoder\n","        # as its input.\n","        prediction_tensor = tf.concat([prediction_tensor, predicted_id], axis=1)\n","\n","    for idx, pred in enumerate(prediction_tensor):\n","        pred_tokens = []\n","        for token in pred:\n","            token_np = token.numpy()\n","            if token_np != end_token:\n","                if token_np == tokenizer.vocab_size:\n","                    word = \"START\"\n","                else:\n","                    word = tokenizer.decode([token_np])#tokenizer.index_word[token_np]\n","                pred_tokens.append(word)\n","            else:\n","                break\n","        pred_sentence = \"\".join(pred_tokens[1:]) #\" \"\n","\n","        query_words = query_sentences[idx].split(\" \")\n","        query = \" \".join(query_words)\n","\n","        print(f\"User: {query}\")\n","        print(f\"Chatbot: {pred_sentence}\")\n","\n","        if output is not None:\n","            bleu_list.append(nltk.translate.bleu_score.sentence_bleu([output[idx].split(\" \")], pred_sentence.split(\" \")))\n","\n","\n","    if output is not None:\n","        print(sum(bleu_list)/len(bleu_list))\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.336141Z","iopub.execute_input":"2023-08-11T03:26:05.336508Z","iopub.status.idle":"2023-08-11T03:26:05.350558Z","shell.execute_reply.started":"2023-08-11T03:26:05.336483Z","shell.execute_reply":"2023-08-11T03:26:05.349774Z"},"trusted":true,"id":"xzsC1t7HxatN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_testdata(sentence_list, tokenizer, start_token=None, end_token=None):\n","    if start_token is not None:\n","        for sentence in sentence_list:\n","            sentence = start_token + \" \" + sentence + \" \" + end_token\n","\n","    test_tokens = tokenizer.texts_to_sequences(sentence_list)\n","    pad_tokens = pad_sequences(test_tokens, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    return pad_tokens\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.351560Z","iopub.execute_input":"2023-08-11T03:26:05.351905Z","iopub.status.idle":"2023-08-11T03:26:05.364429Z","shell.execute_reply.started":"2023-08-11T03:26:05.351880Z","shell.execute_reply":"2023-08-11T03:26:05.363564Z"},"trusted":true,"id":"S8nKz-3TxatN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_testdata_sub(sentence_list, tokenizer):\n","    # Define start and end token to indicate the start and end of a sentence\n","    START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","    sentences_in = []\n","    for i in range(len(sentence_list)):\n","        sentences_in.append(START_TOKEN + tokenizer.encode(sentence_list[i]) + END_TOKEN)\n","\n","    pad_tokens = pad_sequences(sentences_in, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    return pad_tokens"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T04:16:00.304497Z","iopub.execute_input":"2023-08-11T04:16:00.305577Z","iopub.status.idle":"2023-08-11T04:16:00.312428Z","shell.execute_reply.started":"2023-08-11T04:16:00.305536Z","shell.execute_reply":"2023-08-11T04:16:00.311112Z"},"trusted":true,"id":"2ObPu57VxatO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrainingStopCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch%100 == 0:\n","            tf.keras.models.save_model(model, filepath=f\"/kaggle/working/chatbot_{epoch}.h5\", include_optimizer=False)\n","\n","        if logs[\"accuracy\"] > 0.80:\n","            print(\"\\n70% accuracy reached, training stopped!\\n\")\n","            self.model.stop_training = True\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:26:05.379611Z","iopub.execute_input":"2023-08-11T03:26:05.380203Z","iopub.status.idle":"2023-08-11T03:26:05.388642Z","shell.execute_reply.started":"2023-08-11T03:26:05.380173Z","shell.execute_reply":"2023-08-11T03:26:05.387902Z"},"trusted":true,"id":"uwfengb1xatO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    #Data preprocessing constants\n","    SPLIT_RATIO = 0.9\n","    START_TOKEN, END_TOKEN = \"START\", \"END\"\n","    OOV_TOKEN = \"OOV\"\n","\n","\n","    #Transformer constants\n","    EMBEDDING_DIM = 128\n","    NUM_LAYERS = 4\n","    NUM_HEADS = 8\n","    UNITS = 512\n","    DROPOUT = 0.1\n","    EPOCHS = 250\n","    NUM_WORDS = 2**13\n","    TRAINING_SIZE = None\n","\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n","\n","    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","\n","    BATCH_SIZE = 512 * tpu_strategy.num_replicas_in_sync\n","\n","    #open files and save data as variables\n","    with open('/kaggle/input/cornell-moviedialog-corpus/movie_lines.txt', encoding='utf-8', errors='ignore') as f:\n","        movie_lines = f.read().split('\\n')\n","\n","    with open('/kaggle/input/cornell-moviedialog-corpus/movie_conversations.txt', encoding='utf-8', errors='ignore') as f:\n","        movie_convs = f.read().split('\\n')\n","\n","    #preprocess and toknize data\n","    (train_sentences, train_sentences_outputs), (test_sentences, test_outputs) = preprocess(movie_lines, movie_convs, SPLIT_RATIO, START_TOKEN, END_TOKEN, subword=True)\n","\n","    (train_inputs, train_outputs), (test_inputs, test_outputs), tokenizer = sub_tokenize(train_sentences,\\\n","                                                                                     train_sentences_outputs, test_sentences, test_outputs, OOV_TOKEN, NUM_WORDS)\n","\n","    if TRAINING_SIZE is not None:\n","        train_inputs, train_outputs = train_inputs[:TRAINING_SIZE, :], train_outputs[:TRAINING_SIZE, :]\n","\n","    #convert data to tf.data.Dataset\n","    dataset = train_dataset(train_inputs, train_outputs, BATCH_SIZE)\n","\n","    # clear backend\n","    tf.keras.backend.clear_session()\n","\n","    if NUM_WORDS is None:\n","        vocab_size = len(tokenizer.word_index) + 1\n","\n","    else:\n","        #vocab_size = NUM_WORDS    #for word tokenizer\n","        vocab_size = NUM_WORDS + 2    #for subword tokenier\n","\n"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-11T03:26:05.389597Z","iopub.execute_input":"2023-08-11T03:26:05.389862Z","iopub.status.idle":"2023-08-11T03:28:55.026136Z","shell.execute_reply.started":"2023-08-11T03:26:05.389839Z","shell.execute_reply":"2023-08-11T03:28:55.024956Z"},"trusted":true,"id":"5KpTjCsWxatO","outputId":"79892cc6-a185-49eb-fdb9-4d391ccfabf7"},"execution_count":null,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":["#     postn_encoding_check()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:28:55.027392Z","iopub.execute_input":"2023-08-11T03:28:55.027689Z","iopub.status.idle":"2023-08-11T03:28:55.031449Z","shell.execute_reply.started":"2023-08-11T03:28:55.027664Z","shell.execute_reply":"2023-08-11T03:28:55.030616Z"},"trusted":true,"id":"Gy1zy303xatP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","learning_rate = CustomSchedule(EMBEDDING_DIM)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# initialize and compile model\n","with tpu_strategy.scope():\n","    model = Transformer(vocab_size, EMBEDDING_DIM, NUM_LAYERS, NUM_HEADS, UNITS, DROPOUT)\n","\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T03:28:55.032410Z","iopub.execute_input":"2023-08-11T03:28:55.032750Z","iopub.status.idle":"2023-08-11T03:29:01.754961Z","shell.execute_reply.started":"2023-08-11T03:28:55.032725Z","shell.execute_reply":"2023-08-11T03:29:01.753732Z"},"trusted":true,"id":"bZH71O2GxatQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    stop_callback = TrainingStopCallback()\n","    model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks=[stop_callback])"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-11T03:29:01.756153Z","iopub.execute_input":"2023-08-11T03:29:01.756440Z","iopub.status.idle":"2023-08-11T04:04:20.673680Z","shell.execute_reply.started":"2023-08-11T03:29:01.756415Z","shell.execute_reply":"2023-08-11T04:04:20.672408Z"},"trusted":true,"id":"yfseUYTDxatQ","outputId":"52a64dca-12a6-4ca3-9676-91ab8c7e49cd"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/250\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 03:29:30.586331: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-08-11 03:29:31.466077: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"44/44 [==============================] - 90s 751ms/step - loss: 2.9046 - accuracy: 0.0167\nEpoch 2/250\n44/44 [==============================] - 7s 168ms/step - loss: 2.6171 - accuracy: 0.0256\nEpoch 3/250\n44/44 [==============================] - 7s 169ms/step - loss: 2.2076 - accuracy: 0.0256\nEpoch 4/250\n44/44 [==============================] - 7s 168ms/step - loss: 2.0189 - accuracy: 0.0288\nEpoch 5/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.9429 - accuracy: 0.0421\nEpoch 6/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.7919 - accuracy: 0.0549\nEpoch 7/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.6849 - accuracy: 0.0610\nEpoch 8/250\n44/44 [==============================] - 8s 171ms/step - loss: 1.6563 - accuracy: 0.0625\nEpoch 9/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.5826 - accuracy: 0.0690\nEpoch 10/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.5443 - accuracy: 0.0743\nEpoch 11/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.5056 - accuracy: 0.0785\nEpoch 12/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.5219 - accuracy: 0.0766\nEpoch 13/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.4615 - accuracy: 0.0819\nEpoch 14/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.4417 - accuracy: 0.0835\nEpoch 15/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.4194 - accuracy: 0.0853\nEpoch 16/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.3971 - accuracy: 0.0872\nEpoch 17/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.3820 - accuracy: 0.0883\nEpoch 18/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.3596 - accuracy: 0.0902\nEpoch 19/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.3416 - accuracy: 0.0918\nEpoch 20/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.3248 - accuracy: 0.0933\nEpoch 21/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.3092 - accuracy: 0.0946\nEpoch 22/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.2950 - accuracy: 0.0958\nEpoch 23/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.2811 - accuracy: 0.0970\nEpoch 24/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.2672 - accuracy: 0.0981\nEpoch 25/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.2559 - accuracy: 0.0990\nEpoch 26/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.2425 - accuracy: 0.1002\nEpoch 27/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.2321 - accuracy: 0.1010\nEpoch 28/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.2216 - accuracy: 0.1019\nEpoch 29/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.2126 - accuracy: 0.1026\nEpoch 30/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.2037 - accuracy: 0.1034\nEpoch 31/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1962 - accuracy: 0.1041\nEpoch 32/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1892 - accuracy: 0.1046\nEpoch 33/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1807 - accuracy: 0.1054\nEpoch 34/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1729 - accuracy: 0.1061\nEpoch 35/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1668 - accuracy: 0.1067\nEpoch 36/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1610 - accuracy: 0.1071\nEpoch 37/250\n44/44 [==============================] - 8s 171ms/step - loss: 1.1559 - accuracy: 0.1076\nEpoch 38/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1514 - accuracy: 0.1080\nEpoch 39/250\n44/44 [==============================] - 8s 171ms/step - loss: 1.1451 - accuracy: 0.1085\nEpoch 40/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1393 - accuracy: 0.1092\nEpoch 41/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.1335 - accuracy: 0.1098\nEpoch 42/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.1283 - accuracy: 0.1102\nEpoch 43/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1246 - accuracy: 0.1105\nEpoch 44/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.1206 - accuracy: 0.1110\nEpoch 45/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1164 - accuracy: 0.1113\nEpoch 46/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1125 - accuracy: 0.1116\nEpoch 47/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.1087 - accuracy: 0.1121\nEpoch 48/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.1047 - accuracy: 0.1125\nEpoch 49/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.1008 - accuracy: 0.1129\nEpoch 50/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0969 - accuracy: 0.1133\nEpoch 51/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0949 - accuracy: 0.1135\nEpoch 52/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0917 - accuracy: 0.1138\nEpoch 53/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0877 - accuracy: 0.1142\nEpoch 54/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.0843 - accuracy: 0.1145\nEpoch 55/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0811 - accuracy: 0.1149\nEpoch 56/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0787 - accuracy: 0.1152\nEpoch 57/250\n44/44 [==============================] - 8s 170ms/step - loss: 1.0762 - accuracy: 0.1154\nEpoch 58/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0744 - accuracy: 0.1156\nEpoch 59/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0715 - accuracy: 0.1159\nEpoch 60/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0701 - accuracy: 0.1161\nEpoch 61/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0668 - accuracy: 0.1165\nEpoch 62/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0624 - accuracy: 0.1170\nEpoch 63/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0583 - accuracy: 0.1175\nEpoch 64/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0551 - accuracy: 0.1178\nEpoch 65/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0528 - accuracy: 0.1179\nEpoch 66/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0514 - accuracy: 0.1182\nEpoch 67/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0502 - accuracy: 0.1183\nEpoch 68/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0485 - accuracy: 0.1184\nEpoch 69/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0468 - accuracy: 0.1186\nEpoch 70/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0450 - accuracy: 0.1189\nEpoch 71/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0425 - accuracy: 0.1192\nEpoch 72/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0407 - accuracy: 0.1193\nEpoch 73/250\n44/44 [==============================] - 7s 167ms/step - loss: 1.0390 - accuracy: 0.1196\nEpoch 74/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0382 - accuracy: 0.1196\nEpoch 75/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0372 - accuracy: 0.1197\nEpoch 76/250\n44/44 [==============================] - 7s 167ms/step - loss: 1.0353 - accuracy: 0.1199\nEpoch 77/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0343 - accuracy: 0.1200\nEpoch 78/250\n44/44 [==============================] - 7s 167ms/step - loss: 1.0318 - accuracy: 0.1203\nEpoch 79/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0294 - accuracy: 0.1205\nEpoch 80/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0267 - accuracy: 0.1209\nEpoch 81/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0244 - accuracy: 0.1213\nEpoch 82/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0226 - accuracy: 0.1214\nEpoch 83/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0212 - accuracy: 0.1216\nEpoch 84/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0193 - accuracy: 0.1219\nEpoch 85/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0171 - accuracy: 0.1221\nEpoch 86/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0154 - accuracy: 0.1223\nEpoch 87/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0134 - accuracy: 0.1226\nEpoch 88/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0125 - accuracy: 0.1227\nEpoch 89/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0105 - accuracy: 0.1229\nEpoch 90/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0084 - accuracy: 0.1232\nEpoch 91/250\n44/44 [==============================] - 7s 169ms/step - loss: 1.0072 - accuracy: 0.1234\nEpoch 92/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0058 - accuracy: 0.1235\nEpoch 93/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0054 - accuracy: 0.1235\nEpoch 94/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0055 - accuracy: 0.1234\nEpoch 95/250\n44/44 [==============================] - 7s 170ms/step - loss: 1.0041 - accuracy: 0.1235\nEpoch 96/250\n44/44 [==============================] - 7s 168ms/step - loss: 1.0019 - accuracy: 0.1239\nEpoch 97/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9990 - accuracy: 0.1243\nEpoch 98/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9968 - accuracy: 0.1246\nEpoch 99/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9947 - accuracy: 0.1250\nEpoch 100/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9932 - accuracy: 0.1251\nEpoch 101/250\n44/44 [==============================] - 8s 176ms/step - loss: 0.9923 - accuracy: 0.1252\nEpoch 102/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9923 - accuracy: 0.1252\nEpoch 103/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9928 - accuracy: 0.1250\nEpoch 104/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9934 - accuracy: 0.1248\nEpoch 105/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9919 - accuracy: 0.1251\nEpoch 106/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9901 - accuracy: 0.1254\nEpoch 107/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9883 - accuracy: 0.1255\nEpoch 108/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9868 - accuracy: 0.1259\nEpoch 109/250\n44/44 [==============================] - 8s 169ms/step - loss: 0.9859 - accuracy: 0.1260\nEpoch 110/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9867 - accuracy: 0.1258\nEpoch 111/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9874 - accuracy: 0.1257\nEpoch 112/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9870 - accuracy: 0.1257\nEpoch 113/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9858 - accuracy: 0.1258\nEpoch 114/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9854 - accuracy: 0.1258\nEpoch 115/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9869 - accuracy: 0.1257\nEpoch 116/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9873 - accuracy: 0.1255\nEpoch 117/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9844 - accuracy: 0.1259\nEpoch 118/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9804 - accuracy: 0.1265\nEpoch 119/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9761 - accuracy: 0.1272\nEpoch 120/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9732 - accuracy: 0.1276\nEpoch 121/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9709 - accuracy: 0.1280\nEpoch 122/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9695 - accuracy: 0.1282\nEpoch 123/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9693 - accuracy: 0.1282\nEpoch 124/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9688 - accuracy: 0.1282\nEpoch 125/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9683 - accuracy: 0.1283\nEpoch 126/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9689 - accuracy: 0.1282\nEpoch 127/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9704 - accuracy: 0.1278\nEpoch 128/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9718 - accuracy: 0.1275\nEpoch 129/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9725 - accuracy: 0.1274\nEpoch 130/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9711 - accuracy: 0.1275\nEpoch 131/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9698 - accuracy: 0.1278\nEpoch 132/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9685 - accuracy: 0.1279\nEpoch 133/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9678 - accuracy: 0.1282\nEpoch 134/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9669 - accuracy: 0.1283\nEpoch 135/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9651 - accuracy: 0.1286\nEpoch 136/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9634 - accuracy: 0.1289\nEpoch 137/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9611 - accuracy: 0.1291\nEpoch 138/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9595 - accuracy: 0.1294\nEpoch 139/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9590 - accuracy: 0.1294\nEpoch 140/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9589 - accuracy: 0.1295\nEpoch 141/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9591 - accuracy: 0.1294\nEpoch 142/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9597 - accuracy: 0.1293\nEpoch 143/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9592 - accuracy: 0.1293\nEpoch 144/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9592 - accuracy: 0.1294\nEpoch 145/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9589 - accuracy: 0.1293\nEpoch 146/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9584 - accuracy: 0.1294\nEpoch 147/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9587 - accuracy: 0.1294\nEpoch 148/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9600 - accuracy: 0.1292\nEpoch 149/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9596 - accuracy: 0.1292\nEpoch 150/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9583 - accuracy: 0.1293\nEpoch 151/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9555 - accuracy: 0.1299\nEpoch 152/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9535 - accuracy: 0.1300\nEpoch 153/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9514 - accuracy: 0.1304\nEpoch 154/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9498 - accuracy: 0.1307\nEpoch 155/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9505 - accuracy: 0.1306\nEpoch 156/250\n44/44 [==============================] - 8s 171ms/step - loss: 0.9522 - accuracy: 0.1302\nEpoch 157/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9526 - accuracy: 0.1302\nEpoch 158/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9515 - accuracy: 0.1302\nEpoch 159/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9499 - accuracy: 0.1306\nEpoch 160/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9486 - accuracy: 0.1306\nEpoch 161/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9482 - accuracy: 0.1308\nEpoch 162/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9478 - accuracy: 0.1307\nEpoch 163/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9475 - accuracy: 0.1308\nEpoch 164/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9465 - accuracy: 0.1310\nEpoch 165/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9452 - accuracy: 0.1311\nEpoch 166/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9435 - accuracy: 0.1314\nEpoch 167/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9428 - accuracy: 0.1315\nEpoch 168/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9417 - accuracy: 0.1317\nEpoch 169/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9403 - accuracy: 0.1319\nEpoch 170/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9389 - accuracy: 0.1321\nEpoch 171/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9392 - accuracy: 0.1320\nEpoch 172/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9401 - accuracy: 0.1318\nEpoch 173/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9415 - accuracy: 0.1316\nEpoch 174/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9412 - accuracy: 0.1317\nEpoch 175/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9391 - accuracy: 0.1320\nEpoch 176/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9366 - accuracy: 0.1324\nEpoch 177/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9342 - accuracy: 0.1327\nEpoch 178/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9323 - accuracy: 0.1331\nEpoch 179/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9313 - accuracy: 0.1332\nEpoch 180/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9318 - accuracy: 0.1332\nEpoch 181/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9321 - accuracy: 0.1330\nEpoch 182/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9321 - accuracy: 0.1329\nEpoch 183/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9319 - accuracy: 0.1331\nEpoch 184/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9318 - accuracy: 0.1330\nEpoch 185/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9334 - accuracy: 0.1328\nEpoch 186/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9359 - accuracy: 0.1322\nEpoch 187/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9376 - accuracy: 0.1320\nEpoch 188/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9356 - accuracy: 0.1324\nEpoch 189/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9336 - accuracy: 0.1327\nEpoch 190/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9310 - accuracy: 0.1331\nEpoch 191/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9284 - accuracy: 0.1335\nEpoch 192/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9263 - accuracy: 0.1337\nEpoch 193/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9242 - accuracy: 0.1342\nEpoch 194/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9229 - accuracy: 0.1344\nEpoch 195/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9218 - accuracy: 0.1345\nEpoch 196/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9216 - accuracy: 0.1346\nEpoch 197/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9218 - accuracy: 0.1345\nEpoch 198/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9229 - accuracy: 0.1342\nEpoch 199/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9244 - accuracy: 0.1340\nEpoch 200/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9248 - accuracy: 0.1339\nEpoch 201/250\n44/44 [==============================] - 8s 177ms/step - loss: 0.9245 - accuracy: 0.1339\nEpoch 202/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9232 - accuracy: 0.1341\nEpoch 203/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9222 - accuracy: 0.1343\nEpoch 204/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9212 - accuracy: 0.1344\nEpoch 205/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9197 - accuracy: 0.1347\nEpoch 206/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9189 - accuracy: 0.1349\nEpoch 207/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9192 - accuracy: 0.1348\nEpoch 208/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9216 - accuracy: 0.1343\nEpoch 209/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9234 - accuracy: 0.1340\nEpoch 210/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9231 - accuracy: 0.1341\nEpoch 211/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9220 - accuracy: 0.1342\nEpoch 212/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9220 - accuracy: 0.1342\nEpoch 213/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9215 - accuracy: 0.1343\nEpoch 214/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9200 - accuracy: 0.1345\nEpoch 215/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9185 - accuracy: 0.1348\nEpoch 216/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9165 - accuracy: 0.1352\nEpoch 217/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9150 - accuracy: 0.1355\nEpoch 218/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9133 - accuracy: 0.1356\nEpoch 219/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9118 - accuracy: 0.1360\nEpoch 220/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9106 - accuracy: 0.1362\nEpoch 221/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9102 - accuracy: 0.1362\nEpoch 222/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9098 - accuracy: 0.1361\nEpoch 223/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9102 - accuracy: 0.1361\nEpoch 224/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9105 - accuracy: 0.1360\nEpoch 225/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9107 - accuracy: 0.1360\nEpoch 226/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9104 - accuracy: 0.1360\nEpoch 227/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9102 - accuracy: 0.1361\nEpoch 228/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9100 - accuracy: 0.1361\nEpoch 229/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9099 - accuracy: 0.1360\nEpoch 230/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9093 - accuracy: 0.1362\nEpoch 231/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9102 - accuracy: 0.1361\nEpoch 232/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9126 - accuracy: 0.1355\nEpoch 233/250\n44/44 [==============================] - 8s 170ms/step - loss: 0.9152 - accuracy: 0.1351\nEpoch 234/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9162 - accuracy: 0.1351\nEpoch 235/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9152 - accuracy: 0.1353\nEpoch 236/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9125 - accuracy: 0.1357\nEpoch 237/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9091 - accuracy: 0.1362\nEpoch 238/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9068 - accuracy: 0.1366\nEpoch 239/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9051 - accuracy: 0.1369\nEpoch 240/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9036 - accuracy: 0.1371\nEpoch 241/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9025 - accuracy: 0.1373\nEpoch 242/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9019 - accuracy: 0.1374\nEpoch 243/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9017 - accuracy: 0.1373\nEpoch 244/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9016 - accuracy: 0.1373\nEpoch 245/250\n44/44 [==============================] - 7s 170ms/step - loss: 0.9024 - accuracy: 0.1372\nEpoch 246/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9028 - accuracy: 0.1372\nEpoch 247/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9044 - accuracy: 0.1368\nEpoch 248/250\n44/44 [==============================] - 7s 169ms/step - loss: 0.9074 - accuracy: 0.1364\nEpoch 249/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9077 - accuracy: 0.1362\nEpoch 250/250\n44/44 [==============================] - 7s 168ms/step - loss: 0.9079 - accuracy: 0.1362\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7850f020fca0>"},"metadata":{}}]},{"cell_type":"code","source":["    test_sentences_list = []\n","    gt_list = []\n","    for sent in train_sentences:\n","        word_list = sent.split(\" \")\n","        test_sentences_list.append(\" \".join(word_list[1:-1]))\n","\n","    for sent in train_sentences_outputs:\n","        word_list = sent.split(\" \")\n","        gt_list.append(\" \".join(word_list[:])) #word_list[1:-1]\n","\n","    #tokenizer.word_index[START_TOKEN], tokenizer.word_index[END_TOKEN],\n","    prediction(train_inputs[:50,:], test_sentences_list[:50], tokenizer, tokenizer.vocab_size, tokenizer.vocab_size + 1, model, gt_list[:50])"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T04:04:20.675149Z","iopub.execute_input":"2023-08-11T04:04:20.675502Z","iopub.status.idle":"2023-08-11T04:12:24.087427Z","shell.execute_reply.started":"2023-08-11T04:04:20.675472Z","shell.execute_reply":"2023-08-11T04:12:24.085772Z"},"trusted":true,"id":"c_9n_sVAxatQ","outputId":"ce9c23d4-33f5-49ab-8ecb-61ab024b0f7d"},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-08-11 04:04:26.227171: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-08-11 04:04:26.500292: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-08-11 04:04:40.013421: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-08-11 04:04:40.303140: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"User: am here\nChatbot: i am not going to be here in a minute .\nUser: you okay\nChatbot: i am not going to be happy .\nUser: do not know , i just got i got very dizzy . . . i feel dizzy , max\nChatbot: i am not going to be late .\nUser: yes , thank you\nChatbot: i am not going to be here in a minute .\nUser: it over . basic plot\nChatbot: i am not sure i am listening .\nUser: , i told you\nChatbot: i am not going to be here in a minute .\nUser: are going over to her place to make salad and pasta . just , you know , nothing special\nChatbot: i am not going to be here in a few days .\nUser: . . .\nChatbot: i am not sure .\nUser: almost married recently , did not you\nChatbot: i do not know . i do not know .\nUser: beat the odds\nChatbot: i am not going to be here in a minute .\nUser: are a man of the world , fettes , you would not hold me to promise given in drink\nChatbot: i do not know what you are talking about .\nUser: is got a hidden pitbull . maybe she hired someone to kill them\nChatbot: i do not know . i do not know . i do not think i am a writerian .\nUser: , you are okay . you are okay . you are okay\nChatbot: i am not going to be here in a minute .\nUser: , you know that it is improper completely unethical for a licensed psychologist to carry on a romantic relationship with one of his patients\nChatbot: i do not know . i do not think so .\nUser: mean , you tie up our kid and you lock the fucking door ? are . .\nChatbot: . . . and i am glad to see you .\nUser: speak english\nChatbot: i am not going to be here in a minute .\nUser: are not gonna break him with a , bet\nChatbot: i am not going to be here in a minute .\nUser: out of here\nChatbot: i am not going to be here in a minute .\nUser: would be even worse it would be a compromise\nChatbot: i am not going to be here in a minute .\nUser: , well , i think i will stick with what i have got\nChatbot: i am not going to be here in a minute .\nUser: , sue . . . ? i u cannot u\nChatbot: i am not going to be here in a minute .\nUser: , sir\nChatbot: i am not going to be here in a minute .\nUser: this is just the dump site , where did he do the job ? where did he pick her up\nChatbot: i am not sure .\nUser: on the varietal . just get a sense of it . thick ? thin ? watery ? syrupy ? inky ? amber , whatever . .\nChatbot: i am not going to be here in a minute .\nUser: ! and do not think i have not noticed how you have changed . i used to think you were a swell guy well , to be honest i thought you were an\nChatbot: i am not going to be here in the morning .\nUser: me , mrs de moraes ? why should such well connected people as you hire a small time french detective to look for their missing son , mrs de moraes\nChatbot: i am not going to be happy .\nUser: can go to the police . i have blood samples back at the hospital . i can show them\nChatbot: i am not going to be here in a minute .\nUser: with all that pressure , and suction\nChatbot: i am not sure .\nUser: me\nChatbot: i am not going to be here in a minute .\nUser: alright\nChatbot: i am not going to be here in a minute .\nUser: you\nChatbot: i am not going to be here in a minute .\nUser: will you go\nChatbot: i am not sure , i am sure .\nUser: first rule of\nChatbot: you are a very good man ?\nUser: it is impossible\nChatbot: you are not going to be happy , are you ?\nUser: . .\nChatbot: i am not going to be here in a minute .\nUser: pensacola teeny bopper jail bait but built ? ten bucks she wanted . three of us made a deal for , twenty five , see , big goddam bargain\nChatbot: hello , mr . president .\nUser: no fear . this shoshone medicine woman taught me how to make bug repellent tea out of tree root\nChatbot: you are not going to be happy , are you ?\nUser: had better manners as a pig\nChatbot: i am not sure .\nUser: , brad . i think he will be better off doing it his way\nChatbot: i do not know . i do not know . i do not think it is a good idea .\nUser: \nChatbot: i am not going to be here in a minute .\nUser: put him to work\nChatbot: i am not going to be here in a minute .\nUser: is like a living thing . wild . unpredictable\nChatbot: you are not a cop .\nUser: we do not escape , we gotta get the word out about the cash . that is how we will stay alive\nChatbot: i am not going to be here in a minute .\nUser: huh\nChatbot: i am not going to be here in a minute .\nUser: i had to say it ? no , i wanted to say it\nChatbot: i am not going to be here in a minute .\nUser: . . . thank you . but . . . you know you are not supposed to be within four hundred yards of me\nChatbot: i am not sure .\nUser: , sure thing . but what about , like , appliances ? like a little color portable ? boom box\nChatbot: i do not know . i do not know . i do not think it is a good idea .\nUser: , we wont be able to bring you back . its a one way trip . captain , i do not know if the transporter . .\nChatbot: i am not going to be here in the morning . i am going to be a good man .\nUser: \nChatbot: i am not sure .\nUser: \nChatbot: i am not going to be here in a minute .\n6.815459124335769e-80\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 2-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 3-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":["print(test_sentences_list[:5])"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T04:12:24.088870Z","iopub.execute_input":"2023-08-11T04:12:24.089210Z","iopub.status.idle":"2023-08-11T04:12:24.094721Z","shell.execute_reply.started":"2023-08-11T04:12:24.089181Z","shell.execute_reply":"2023-08-11T04:12:24.093572Z"},"trusted":true,"id":"Mf8ksiLJxatR","outputId":"f43ada55-a84e-455c-df02-e503942eea16"},"execution_count":null,"outputs":[{"name":"stdout","text":"['am here', 'you okay', 'do not know , i just got i got very dizzy . . . i feel dizzy , max', 'yes , thank you', 'it over . basic plot']\n","output_type":"stream"}]},{"cell_type":"code","source":["#     test_input_sentences = [\"Hello, what's up?\", \"What is your plan?\", \"Are you going to the gym now?\", \"When is the book due\", \"What's the point?\", \"I'm visiting my parents tomorrow\", \"It'll be windy next week\"]\n","#     test_inputs = preprocess_testdata(test_input_sentences, tokenizer, START_TOKEN, END_TOKEN)\n","#     prediction(test_inputs, test_input_sentences, tokenizer, tokenizer.word_index[START_TOKEN], tokenizer.word_index[END_TOKEN], model)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T04:12:24.095836Z","iopub.execute_input":"2023-08-11T04:12:24.096122Z","iopub.status.idle":"2023-08-11T04:12:24.109456Z","shell.execute_reply.started":"2023-08-11T04:12:24.096097Z","shell.execute_reply":"2023-08-11T04:12:24.108462Z"},"trusted":true,"id":"nM8wPguDxatR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    test_input_sentences = [\"Hello, what's up?\", \"What is your plan?\", \"Are you going to the gym now?\", \"When is the book due\", \"What's the point?\", \"I'm visiting my parents tomorrow\", \"It'll be windy next week\"]\n","    test_inputs = preprocess_testdata_sub(test_input_sentences, tokenizer)\n","    prediction(test_inputs, test_input_sentences, tokenizer, tokenizer.vocab_size, tokenizer.vocab_size+1, model)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T04:16:46.653780Z","iopub.execute_input":"2023-08-11T04:16:46.654248Z","iopub.status.idle":"2023-08-11T04:20:36.638562Z","shell.execute_reply.started":"2023-08-11T04:16:46.654214Z","shell.execute_reply":"2023-08-11T04:20:36.636941Z"},"trusted":true,"id":"HPafu3FbxatS","outputId":"f91eb2d7-c3d8-4f2c-f78e-bebdb5b73849"},"execution_count":null,"outputs":[{"name":"stdout","text":"User: Hello, what's up?\nChatbot: i do not think so .\nUser: What is your plan?\nChatbot: i am not going to deny the lousy door !\nUser: Are you going to the gym now?\nChatbot: i am not sure .\nUser: When is the book due\nChatbot: he is a good man .\nUser: What's the point?\nChatbot: i am not going to be happy .\nUser: I'm visiting my parents tomorrow\nChatbot: . . . and i will be fine . i will be careful .\nUser: It'll be windy next week\nChatbot: i am not sure .\n","output_type":"stream"}]},{"cell_type":"markdown","source":[],"metadata":{"id":"jqvLhysixatS"}},{"cell_type":"markdown","source":[],"metadata":{"id":"nzoWFm6gxatU"}},{"cell_type":"markdown","source":[],"metadata":{"id":"TLwCqD5BxatU"}}]}