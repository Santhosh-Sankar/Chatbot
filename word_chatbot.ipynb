{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import re\n","import random\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import nltk\n","\n","tf.keras.utils.set_random_seed(1234)\n","\n","MAX_SENTENCE_LEN = 40\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:41.457237Z","iopub.execute_input":"2023-08-10T22:20:41.458013Z","iopub.status.idle":"2023-08-10T22:20:42.748021Z","shell.execute_reply.started":"2023-08-10T22:20:41.457971Z","shell.execute_reply":"2023-08-10T22:20:42.747111Z"},"trusted":true,"id":"YNr9Q7xixvQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","\n","    # remove unnecessary characters in sentences and v\n","\n","    text = text.lower().strip()\n","    #Seperate ?.!, with spaces\n","    text = re.sub(r\"([?.!,])\", r\" \\1 \", text)\n","    #Replace extra spaces with a single space\n","    text = re.sub(r'[\" \"]+', \" \", text)\n","\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"what is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"there's\", \"there is\", text)\n","    text = re.sub(r\"how's\", \"how is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'ve\", \" have\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"n'\", \"ng\", text)\n","    text = re.sub(r\"'bout\", \"about\", text)\n","    text = re.sub(r\"'til\", \"until\", text)\n","    text = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", text)\n","\n","    #Remove trailing spaces\n","    text = text.strip()\n","\n","    return text"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.749721Z","iopub.execute_input":"2023-08-10T22:20:42.750326Z","iopub.status.idle":"2023-08-10T22:20:42.770394Z","shell.execute_reply.started":"2023-08-10T22:20:42.750294Z","shell.execute_reply":"2023-08-10T22:20:42.769617Z"},"trusted":true,"id":"ya2S4RtmxvQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(movie_lines, movie_convs, split_ratio, start_tok, end_tok, subword=False):\n","    #map line ids to line/dialog\n","    conv_map = {}\n","    for line in movie_lines:\n","        if len(line) != 0:\n","            line_split = line.split(\" +++$+++ \")\n","            conv_map[line_split[0]] = line_split[4]\n","\n","    #create list containing lists of conversations\n","    convid_list = []\n","    for line in movie_convs:\n","        if len(line) != 0:\n","            conv = line.split(\" +++$+++ \")[-1][1:-1].strip(\"'\").split(\"', '\")\n","            convid_list.append(conv)\n","\n","    #split into questions and answers\n","    input, response  = [], []\n","\n","    for conv in convid_list:\n","        for i in range(len(conv)-1):\n","            input.append(clean_text(conv_map[conv[i]]))\n","            response.append(clean_text(conv_map[conv[i+1]]))\n","\n","    #Segregating sentences which habe less than or eqqual to 100 words for faster training\n","    filtered_input, filtered_response = [], []\n","\n","    num_qnans_pairs = len(input)\n","\n","    if not subword:\n","        for i in range(num_qnans_pairs):\n","            if len(input[i].split()) <= MAX_SENTENCE_LEN-2 and len(response[i].split()) <= MAX_SENTENCE_LEN-2:\n","                    filtered_input.append(start_tok + \" \" + input[i] + \" \" + end_tok)\n","                    filtered_response.append(start_tok + \" \" + response[i] + \" \" + end_tok)\n","    else:\n","        for i in range(num_qnans_pairs):\n","            if len(input[i].split()) <= MAX_SENTENCE_LEN-2 and len(response[i].split()) <= MAX_SENTENCE_LEN-2:\n","                    filtered_input.append(input[i])\n","                    filtered_response.append(response[i])\n","\n","\n","    #Split to training and test set\n","    training_size = int(len(filtered_input) * split_ratio)\n","\n","    #Shuffe the qn answer pairs\n","    idx = np.arange(len(filtered_input))\n","    random.shuffle(idx)\n","\n","    shuffled_input, shuffled_response = [], []\n","\n","    for i in idx:\n","        shuffled_input.append(filtered_input[i])\n","        shuffled_response.append(filtered_response[i])\n","\n","    train_input, train_responses = shuffled_input[:training_size], shuffled_response[:training_size]\n","    test_input, test_responses = shuffled_input[training_size:], shuffled_response[training_size:]\n","\n","    return (train_input, train_responses), (test_input, test_responses)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.771834Z","iopub.execute_input":"2023-08-10T22:20:42.772149Z","iopub.status.idle":"2023-08-10T22:20:42.795838Z","shell.execute_reply.started":"2023-08-10T22:20:42.772121Z","shell.execute_reply":"2023-08-10T22:20:42.794991Z"},"trusted":true,"id":"lTtFVSXhxvQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize(train_inputs, train_outputs, test_inputs, test_outputs, oov_tok, num_words):\n","    if num_words is not None:\n","        tokenizer = Tokenizer(num_words=num_words, oov_token=oov_tok, lower=False, filters='\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n',)\n","    else:\n","        tokenizer = Tokenizer(oov_token=oov_tok, lower=False)\n","\n","    tokenizer.fit_on_texts(train_inputs+train_outputs)\n","\n","    train_input_seq = tokenizer.texts_to_sequences(train_inputs)\n","    train_output_seq = tokenizer.texts_to_sequences(train_outputs)\n","\n","    test_input_seq = tokenizer.texts_to_sequences(test_inputs)\n","    test_output_seq = tokenizer.texts_to_sequences(test_outputs)\n","\n","    train_input_seq_pad = pad_sequences(train_input_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    train_output_seq_pad = pad_sequences(train_output_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    test_input_seq_pad = pad_sequences(test_input_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    test_output_seq_pad = pad_sequences(test_output_seq, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    return (train_input_seq_pad, train_output_seq_pad), (test_input_seq_pad, test_output_seq_pad), tokenizer"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.797927Z","iopub.execute_input":"2023-08-10T22:20:42.798221Z","iopub.status.idle":"2023-08-10T22:20:42.812728Z","shell.execute_reply.started":"2023-08-10T22:20:42.798194Z","shell.execute_reply":"2023-08-10T22:20:42.811880Z"},"trusted":true,"id":"n9Pm6JQkxvQq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sub_tokenize(train_inputs, train_outputs, test_inputs, test_outputs, oov_tok, num_words):\n","    # Build tokenizer using tfds for both questions and answers\n","    tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","        train_inputs+train_outputs, target_vocab_size=num_words)\n","\n","    # Define start and end token to indicate the start and end of a sentence\n","    START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","    train_in, train_out, test_in, test_out = [], [], [], []\n","    for i in range(len(train_inputs)):\n","        train_in.append(START_TOKEN + tokenizer.encode(train_inputs[i]) + END_TOKEN)\n","        train_out.append(START_TOKEN + tokenizer.encode(train_outputs[i]) + END_TOKEN)\n","\n","    for i in range(len(test_inputs)):\n","        test_in.append(START_TOKEN + tokenizer.encode(test_inputs[i]) + END_TOKEN)\n","        test_out.append(START_TOKEN + tokenizer.encode(test_outputs[i]) + END_TOKEN)\n","\n","\n","    pad_train_inputs = pad_sequences(train_in, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    pad_train_outputs = pad_sequences(train_out, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    pad_test_inputs = pad_sequences(test_in, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    pad_test_outputs = pad_sequences(test_out, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","\n","    return (pad_train_inputs, pad_train_outputs), (pad_test_inputs, pad_test_outputs), tokenizer"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.813839Z","iopub.execute_input":"2023-08-10T22:20:42.814151Z","iopub.status.idle":"2023-08-10T22:20:42.831528Z","shell.execute_reply.started":"2023-08-10T22:20:42.814123Z","shell.execute_reply":"2023-08-10T22:20:42.830567Z"},"trusted":true,"id":"LBR5zfCUxvQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_dataset(train_in, train_out, batch_size):\n","    #END token removed from decoder (as there's nothing to predict after the token) input and START token removed from output\n","    dataset = tf.data.Dataset.from_tensor_slices(({\"encoder_in\":train_in, \"decoder_in\":train_out[:,:-1]}, {\"outputs\": train_out[:, 1:]}))\n","    dataset = dataset.cache()\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.832669Z","iopub.execute_input":"2023-08-10T22:20:42.832986Z","iopub.status.idle":"2023-08-10T22:20:42.864261Z","shell.execute_reply.started":"2023-08-10T22:20:42.832958Z","shell.execute_reply":"2023-08-10T22:20:42.863378Z"},"trusted":true,"id":"We_HGWmIxvQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_pad_mask(input):\n","\n","    pad_mask = tf.cast(tf.math.equal(input, 0), tf.float32)\n","    pad_mask = tf.expand_dims(tf.expand_dims(pad_mask, axis=1), axis=1)\n","    return pad_mask\n","\n","def create_look_ahead_mask(input):\n","\n","    seq_len = tf.shape(input)[1]\n","    pad_mask = create_pad_mask(input)\n","\n","    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","    pad_and_look_ahead_mask = tf.maximum(pad_mask, look_ahead_mask)\n","    return pad_and_look_ahead_mask\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.865382Z","iopub.execute_input":"2023-08-10T22:20:42.865709Z","iopub.status.idle":"2023-08-10T22:20:42.886367Z","shell.execute_reply.started":"2023-08-10T22:20:42.865666Z","shell.execute_reply":"2023-08-10T22:20:42.885485Z"},"trusted":true,"id":"gHAvgRXAxvQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class multiHeadAttn_layer(tf.keras.layers.Layer):\n","    def __init__(self, num_heads, embedding_dim, **kwargs):\n","        #check if nembedding dim divisible by mum_heads\n","        assert embedding_dim%num_heads == 0\n","\n","        super(multiHeadAttn_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.embedding_dim_per_head = self.embedding_dim // self.num_heads\n","\n","        self.query_transform = tf.keras.layers.Dense(self.embedding_dim)\n","        self.key_transform = tf.keras.layers.Dense(self.embedding_dim)\n","        self.value_transform = tf.keras.layers.Dense(self.embedding_dim)\n","\n","        self.permute = tf.keras.layers.Permute((2, 1, 3))\n","        self.dense = tf.keras.layers.Dense(self.embedding_dim)\n","\n","\n","    def get_config(self):\n","        config = super(multiHeadAttn_layer, self).get_config()\n","\n","        #Update config with new layer attributes to make loading models easier\n","        config.update({\"num_heads\": self.num_heads, \"embedding_dim\": self.embedding_dim})\n","\n","        return config\n","\n","    def call(self, query, key, value, mask):\n","\n","        batch_size, q_seq_len, k_seq_len= tf.shape(query)[0], tf.shape(query)[1], tf.shape(key)[1]\n","\n","        #Transform key, query, value\n","        query_transformed = self.query_transform(query)\n","        key_transformed = self.key_transform(key)\n","        value_transformed = self.value_transform(value)\n","\n","        #Reshape  and permute dimensions to perform dot product per head\n","        query_per_head = tf.reshape(query_transformed, (batch_size, q_seq_len, self.num_heads, self.embedding_dim_per_head))\n","        key_per_head = tf.reshape(key_transformed, (batch_size, k_seq_len, self.num_heads, self.embedding_dim_per_head))\n","        value_per_head = tf.reshape(value_transformed, (batch_size, k_seq_len, self.num_heads, self.embedding_dim_per_head))\n","\n","        query_per_head = self.permute(query_per_head)\n","        key_per_head = self.permute(key_per_head)\n","        value_per_head = self.permute(value_per_head)\n","\n","        query_per_head = tf.reshape(query_per_head, (batch_size*self.num_heads, q_seq_len, self.embedding_dim_per_head))\n","        key_per_head = tf.reshape(key_per_head, (batch_size*self.num_heads, k_seq_len, self.embedding_dim_per_head))\n","        value_per_head = tf.reshape(value_per_head, (batch_size*self.num_heads, k_seq_len, self.embedding_dim_per_head))\n","\n","        #Dot product between key and query to find similarities\n","        dot_prod = tf.matmul(query_per_head, key_per_head, transpose_b=True)/ tf.math.sqrt(tf.cast(self.embedding_dim_per_head, dtype=tf.float32))\n","\n","        #To avoid considering the padded tokens and future tokens\n","        dot_prod_reshaped = tf.reshape(dot_prod, (batch_size, self.num_heads, q_seq_len, k_seq_len))\n","\n","        dot_prod_reshaped += mask * -1e9\n","\n","        dot_prod = tf.reshape(dot_prod_reshaped, (batch_size*self.num_heads, q_seq_len, k_seq_len))\n","\n","        #Findding attention weights\n","        attn_weights = tf.nn.softmax(dot_prod, axis=-1)\n","\n","        attn_out = tf.matmul(attn_weights, value_per_head)\n","\n","        #Reshaping the output back to the original shape\n","        attn_out_reshaped = tf.reshape(attn_out, (batch_size, self.num_heads, q_seq_len, self.embedding_dim_per_head))\n","\n","        attn_out_permuted = self.permute(attn_out_reshaped)\n","\n","        attn_out = tf.reshape(attn_out_permuted, (batch_size, q_seq_len, self.embedding_dim))\n","\n","        #Final linear dense layer\n","        output = self.dense(attn_out)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.887548Z","iopub.execute_input":"2023-08-10T22:20:42.887867Z","iopub.status.idle":"2023-08-10T22:20:42.910976Z","shell.execute_reply.started":"2023-08-10T22:20:42.887839Z","shell.execute_reply":"2023-08-10T22:20:42.910055Z"},"trusted":true,"id":"fpT1o6SpxvQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, max_len=10000, **kwargs):\n","        super(PositionalEncoding_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.max_len = max_len\n","\n","\n","    def get_config(self):\n","        config = super(PositionalEncoding_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"max_len\": self.max_len})\n","\n","        return config\n","\n","    def call(self, input):\n","        batch_size = tf.shape(input)[0]\n","        seq_len = tf.shape(input)[1]\n","\n","        #denominator\n","        den = self.max_len**(tf.range(self.embedding_dim, delta=2, dtype=tf.float32)/self.embedding_dim)\n","        den_stacked = tf.expand_dims(tf.expand_dims(den, axis=0), axis=1)\n","        den_stacked = tf.repeat(tf.repeat(den_stacked, repeats=seq_len, axis=1), repeats=batch_size, axis=0)\n","\n","        #numerator\n","        num_stacked = tf.expand_dims(tf.expand_dims(tf.range(seq_len, dtype=tf.float32), axis=0), axis=2)\n","        num_stacked = tf.repeat(num_stacked, repeats=batch_size, axis=0)\n","\n","        inner_term = num_stacked / den_stacked\n","\n","        postn_encoding = tf.stack([tf.sin(inner_term), tf.cos(inner_term)], axis=-1)\n","\n","        postn_encoding = tf.reshape(postn_encoding, (batch_size, seq_len, self.embedding_dim))\n","\n","        output = input + postn_encoding\n","\n","        # return postn_encoding\n","        return output, postn_encoding\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.912102Z","iopub.execute_input":"2023-08-10T22:20:42.912401Z","iopub.status.idle":"2023-08-10T22:20:42.928716Z","shell.execute_reply.started":"2023-08-10T22:20:42.912373Z","shell.execute_reply":"2023-08-10T22:20:42.927922Z"},"trusted":true,"id":"_khl64_6xvQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def postn_encoding_check():\n","\n","    input = tf.ones((2, 10, 64))\n","    _, out = PositionalEncoding_layer(64)(input)\n","\n","    plt.pcolormesh(out[0])\n","    plt.xlabel(\"Depth\")\n","    plt.xlim((0, 64))\n","    plt.ylabel(\"Position\")\n","    plt.colorbar()\n","    plt.show()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.933194Z","iopub.execute_input":"2023-08-10T22:20:42.933501Z","iopub.status.idle":"2023-08-10T22:20:42.944838Z","shell.execute_reply.started":"2023-08-10T22:20:42.933473Z","shell.execute_reply":"2023-08-10T22:20:42.943999Z"},"trusted":true,"id":"Y4mpFzQ9xvQy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class feed_forward_network(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_units, **kwargs):\n","        super(feed_forward_network, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_units = num_units\n","\n","        self.dense1 = tf.keras.layers.Dense(self.num_units, activation=tf.nn.relu)\n","        self.dense2 = tf.keras.layers.Dense(self.embedding_dim)\n","\n","    def get_config(self):\n","        config = super(feed_forward_network, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_units\": self.num_units})\n","        return config\n","\n","\n","    def call(self, input):\n","        dense_out1 = self.dense1(input)\n","        dense_out2 = self.dense2(dense_out1)\n","        return dense_out2"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.945898Z","iopub.execute_input":"2023-08-10T22:20:42.946193Z","iopub.status.idle":"2023-08-10T22:20:42.958776Z","shell.execute_reply.started":"2023-08-10T22:20:42.946166Z","shell.execute_reply":"2023-08-10T22:20:42.957939Z"},"trusted":true,"id":"etxj2vUYxvQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class encoder_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(encoder_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.multiheadAttn = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","        self.feed_forward = feed_forward_network(self.embedding_dim, self.num_dense_units)\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","        self.add = tf.keras.layers.Add()\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(encoder_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","        return config\n","\n","    def call(self, input, mask):\n","\n","        attn_out = self.multiheadAttn(input, input, input, mask)\n","        dropout_out1 = self.dropout(attn_out)\n","        res_out1 = self.add([input, dropout_out1])\n","        norm_out1 = self.layernorm(res_out1)\n","\n","        feed_forward_out = self.feed_forward(norm_out1)\n","        dropout_out2 = self.dropout(feed_forward_out)\n","        res_out2 = self.add([norm_out1, dropout_out2])\n","        norm_out2 = self.layernorm(res_out2)\n","\n","        return norm_out2\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.959928Z","iopub.execute_input":"2023-08-10T22:20:42.960243Z","iopub.status.idle":"2023-08-10T22:20:42.976352Z","shell.execute_reply.started":"2023-08-10T22:20:42.960214Z","shell.execute_reply":"2023-08-10T22:20:42.975434Z"},"trusted":true,"id":"i3kOBUq8xvQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_encoding_layers, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(Encoder, self).__init__(**kwargs)\n","        self.num_encoding_layers =  num_encoding_layers\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.encoder_layers_list = [encoder_layer(self.embedding_dim, self.num_heads, self.num_dense_units, self.dropout_rate) for _ in range(self.num_encoding_layers)]\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(Encoder, self).get_config()\n","        config.update({\"num_encoding_layers\": self.num_encoding_layers, \"embedding_dim\": self.embedding_dim,\\\n","                       \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, mask):\n","\n","        x = input\n","        for layer in self.encoder_layers_list:\n","            x = layer(x, mask)\n","        output = self.layernorm(x)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.977436Z","iopub.execute_input":"2023-08-10T22:20:42.977754Z","iopub.status.idle":"2023-08-10T22:20:42.993568Z","shell.execute_reply.started":"2023-08-10T22:20:42.977726Z","shell.execute_reply":"2023-08-10T22:20:42.992542Z"},"trusted":true,"id":"N_ZPhHyBxvQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class decoder_layer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(decoder_layer, self).__init__(**kwargs)\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.multiHeadAttn_self = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","        self.multiHeadAttn_cross = multiHeadAttn_layer(self.num_heads, self.embedding_dim)\n","\n","        self.feed_forward = feed_forward_network(self.embedding_dim, self.num_dense_units)\n","\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","        self.add = tf.keras.layers.Add()\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","\n","    def get_config(self):\n","        config = super(decoder_layer, self).get_config()\n","        config.update({\"embedding_dim\": self.embedding_dim, \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, encoder_output, look_ahead_mask, pad_mask):\n","\n","        self_attn_out = self.multiHeadAttn_self(input, input, input, look_ahead_mask)\n","        dropout_out1 = self.dropout(self_attn_out)\n","        res_out1 = self.add([input, dropout_out1])\n","        norm_out1 = self.layernorm(res_out1)\n","\n","        cross_attn_out = self.multiHeadAttn_cross(norm_out1, encoder_output, encoder_output, pad_mask)\n","        dropout_out2 = self.dropout(cross_attn_out)\n","        res_out2 = self.add([norm_out1, dropout_out2])\n","        norm_out2 = self.layernorm(res_out2)\n","\n","        feed_forward_out = self.feed_forward(norm_out2)\n","        dropout_out3 = self.dropout(feed_forward_out)\n","        res_out3 = self.add([norm_out2, dropout_out3])\n","        norm_out3 = self.layernorm(res_out3)\n","\n","        return norm_out3\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:42.995170Z","iopub.execute_input":"2023-08-10T22:20:42.995479Z","iopub.status.idle":"2023-08-10T22:20:43.024101Z","shell.execute_reply.started":"2023-08-10T22:20:42.995451Z","shell.execute_reply":"2023-08-10T22:20:43.022971Z"},"trusted":true,"id":"EV_2npzHxvQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_decoding_layers, embedding_dim, num_heads, num_dense_units, dropout_rate, **kwargs):\n","        super(Decoder, self).__init__(**kwargs)\n","        self.num_decoding_layers =  num_decoding_layers\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.num_dense_units = num_dense_units\n","        self.dropout_rate = dropout_rate\n","\n","        self.decoder_layers_list = [decoder_layer(self.embedding_dim, self.num_heads, self.num_dense_units, self.dropout_rate) for _ in range(self.num_decoding_layers)]\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def get_config(self):\n","        config = super(Decoder, self).get_config()\n","        config.update({\"num_decoding_layers\": self.num_decoding_layers, \"embedding_dim\": self.embedding_dim,\\\n","                       \"num_heads\": self.num_heads, \"num_dense_units\": self.num_dense_units, \"dropout_rate\": self.dropout_rate})\n","\n","        return config\n","\n","    def call(self, input, encoder_output, look_ahead_mask, pad_mask):\n","\n","        x = input\n","        for layer in self.decoder_layers_list:\n","            x = layer(x, encoder_output, look_ahead_mask, pad_mask)\n","        output = self.layernorm(x)\n","\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.025381Z","iopub.execute_input":"2023-08-10T22:20:43.025729Z","iopub.status.idle":"2023-08-10T22:20:43.057735Z","shell.execute_reply.started":"2023-08-10T22:20:43.025670Z","shell.execute_reply":"2023-08-10T22:20:43.056872Z"},"trusted":true,"id":"Y3CGb1pJxvQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Transformer(vocab_size, embedding_dim, num_layers, num_heads, num_dense_units, dropout_rate):\n","\n","    #Tokenized encoder and decoder inputs\n","    encoder_inputs = tf.keras.Input(shape=(None,), name=\"encoder_in\")\n","    decoder_inputs = tf.keras.Input(shape=(None,), name=\"decoder_in\")\n","\n","    #Create masks\n","    encoder_pad_mask = tf.keras.layers.Lambda(create_pad_mask, output_shape=(1, 1, None))(encoder_inputs)\n","    decoder_pad_mask = tf.keras.layers.Lambda(create_pad_mask, output_shape=(1, 1, None))(encoder_inputs)\n","    decoder_look_ahead_mask=  tf.keras.layers.Lambda(create_look_ahead_mask, output_shape=(1, None, None))(decoder_inputs)\n","\n","    #Embed the inputs\n","    embed_encoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim)(encoder_inputs)\n","    embed_decoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim)(decoder_inputs)\n","\n","    #Positional Encoding\n","    encoder_inputs_postn_encoded, _ = PositionalEncoding_layer(embedding_dim)(embed_encoder_inputs)\n","    decoder_inputs_postn_encoded, _ = PositionalEncoding_layer(embedding_dim)(embed_decoder_inputs)\n","\n","    #Encoder\n","    encoder_outputs = Encoder(num_layers, embedding_dim, num_heads, num_dense_units, dropout_rate)(encoder_inputs_postn_encoded, encoder_pad_mask)\n","\n","    #Decoder\n","    decoder_outputs = Decoder(num_layers, embedding_dim, num_heads, num_dense_units, dropout_rate)(decoder_inputs_postn_encoded, encoder_outputs,\\\n","                                                                                                   decoder_look_ahead_mask, decoder_pad_mask)\n","\n","    #Linear layer\n","    logits = tf.keras.layers.Dense(vocab_size, name=\"outputs\")(decoder_outputs)\n","\n","    return tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=logits)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.058934Z","iopub.execute_input":"2023-08-10T22:20:43.059238Z","iopub.status.idle":"2023-08-10T22:20:43.088514Z","shell.execute_reply.started":"2023-08-10T22:20:43.059211Z","shell.execute_reply":"2023-08-10T22:20:43.087672Z"},"trusted":true,"id":"S-oO1V5cxvQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loss_function(y_true, y_pred):\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LEN - 1))\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")(y_true, y_pred)\n","\n","    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","    loss = tf.multiply(loss, mask)\n","\n","    return tf.reduce_mean(loss)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.089599Z","iopub.execute_input":"2023-08-10T22:20:43.089949Z","iopub.status.idle":"2023-08-10T22:20:43.110871Z","shell.execute_reply.started":"2023-08-10T22:20:43.089912Z","shell.execute_reply":"2023-08-10T22:20:43.109996Z"},"trusted":true,"id":"5JXhplEIxvQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LEN - 1))\n","\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.112014Z","iopub.execute_input":"2023-08-10T22:20:43.112322Z","iopub.status.idle":"2023-08-10T22:20:43.139972Z","shell.execute_reply.started":"2023-08-10T22:20:43.112294Z","shell.execute_reply":"2023-08-10T22:20:43.139091Z"},"trusted":true,"id":"WG0DG0vkxvQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, embedding_dim, warmup_steps=3000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.embedding_dim = tf.constant(embedding_dim, dtype=tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def get_config(self):\n","        return {\"d_model\": self.d_model, \"warmup_steps\": self.warmup_steps}\n","\n","    def __call__(self, step):\n","        step = tf.cast(step, dtype=tf.float32)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps**-1.5)\n","\n","        lr = tf.math.multiply(tf.math.rsqrt(self.embedding_dim), tf.math.minimum(arg1, arg2))\n","\n","        return lr"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.141114Z","iopub.execute_input":"2023-08-10T22:20:43.141508Z","iopub.status.idle":"2023-08-10T22:20:43.152604Z","shell.execute_reply.started":"2023-08-10T22:20:43.141479Z","shell.execute_reply":"2023-08-10T22:20:43.151739Z"},"trusted":true,"id":"3CTULOM_xvQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction(input, query_sentences, tokenizer, start_token, end_token, model, output=None):\n","\n","    num_inputs = input.shape[0]\n","\n","    bleu_list = []\n","    prediction_list = []\n","    for _ in range(num_inputs):\n","        prediction_list.append([start_token])\n","\n","    prediction_tensor = tf.convert_to_tensor(prediction_list, dtype=tf.int32)\n","\n","    input = tf.convert_to_tensor(input, dtype=tf.int32)\n","\n","    for i in range(MAX_SENTENCE_LEN):\n","        model_out = model.predict([input, prediction_tensor], verbose=0)\n","\n","        last_words = model_out[:, -1:, :]\n","        predicted_id = tf.cast(tf.argmax(last_words, axis=-1), tf.int32)\n","\n","        # concatenated the predicted_id to the output which is given to the decoder\n","        # as its input.\n","        prediction_tensor = tf.concat([prediction_tensor, predicted_id], axis=1)\n","\n","    for idx, pred in enumerate(prediction_tensor):\n","        pred_tokens = []\n","        for token in pred:\n","            token_np = token.numpy()\n","            if token_np != end_token:\n","                word = tokenizer.index_word[token_np]\n","                pred_tokens.append(word)\n","            else:\n","                break\n","        pred_sentence = \" \".join(pred_tokens[1:])\n","\n","        query_words = query_sentences[idx].split(\" \")\n","        query = \" \".join(query_words)\n","\n","        print(f\"User: {query}\")\n","        print(f\"Chatbot: {pred_sentence}\")\n","\n","        if output is not None:\n","            bleu_list.append(nltk.translate.bleu_score.sentence_bleu([output[idx].split(\" \")], pred_sentence.split(\" \")))\n","\n","\n","    if output is not None:\n","        print(sum(bleu_list)/len(bleu_list))\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:27:48.568834Z","iopub.execute_input":"2023-08-10T23:27:48.569880Z","iopub.status.idle":"2023-08-10T23:27:48.584168Z","shell.execute_reply.started":"2023-08-10T23:27:48.569824Z","shell.execute_reply":"2023-08-10T23:27:48.582923Z"},"trusted":true,"id":"DNgHuTcnxvQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_testdata(sentence_list, tokenizer, start_token=None, end_token=None):\n","    if start_token is not None:\n","        for sentence in sentence_list:\n","            sentence = start_token + \" \" + sentence + \" \" + end_token\n","\n","    test_tokens = tokenizer.texts_to_sequences(sentence_list)\n","    pad_tokens = pad_sequences(test_tokens, padding=\"post\", maxlen=MAX_SENTENCE_LEN)\n","    return pad_tokens\n",""],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.174484Z","iopub.execute_input":"2023-08-10T22:20:43.174811Z","iopub.status.idle":"2023-08-10T22:20:43.189414Z","shell.execute_reply.started":"2023-08-10T22:20:43.174782Z","shell.execute_reply":"2023-08-10T22:20:43.188595Z"},"trusted":true,"id":"6WPtvVYTxvQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrainingStopCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch%100 == 0:\n","            tf.keras.models.save_model(model, filepath=f\"/kaggle/working/chatbot_{epoch}.h5\", include_optimizer=False)\n","\n","        if logs[\"accuracy\"] > 0.7:\n","            print(\"\\n70% accuracy reached, training stopped!\\n\")\n","            self.model.stop_training = True\n",""],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:20:43.190537Z","iopub.execute_input":"2023-08-10T22:20:43.191122Z","iopub.status.idle":"2023-08-10T22:20:43.203183Z","shell.execute_reply.started":"2023-08-10T22:20:43.191092Z","shell.execute_reply":"2023-08-10T22:20:43.202314Z"},"trusted":true,"id":"1qRII3_NxvQ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    #Data preprocessing constants\n","    SPLIT_RATIO = 0.9\n","    START_TOKEN, END_TOKEN = \"START\", \"END\"\n","    OOV_TOKEN = \"OOV\"\n","\n","\n","    #Transformer constants\n","    EMBEDDING_DIM = 128\n","    NUM_LAYERS = 4\n","    NUM_HEADS = 8\n","    UNITS = 512\n","    DROPOUT = 0.1\n","    EPOCHS = 250\n","    NUM_WORDS = None\n","    TRAINING_SIZE = None\n","\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n","\n","    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","\n","    BATCH_SIZE = 512 * tpu_strategy.num_replicas_in_sync\n","\n","    #open files and save data as variables\n","    with open('/kaggle/input/cornell-moviedialog-corpus/movie_lines.txt', encoding='utf-8', errors='ignore') as f:\n","        movie_lines = f.read().split('\\n')\n","\n","    with open('/kaggle/input/cornell-moviedialog-corpus/movie_conversations.txt', encoding='utf-8', errors='ignore') as f:\n","        movie_convs = f.read().split('\\n')\n","\n","    #preprocess and toknize data\n","    (train_sentences, train_sentences_outputs), (test_sentences, test_outputs) = preprocess(movie_lines, movie_convs, SPLIT_RATIO, START_TOKEN, END_TOKEN, subword=False)\n","\n","    (train_inputs, train_outputs), (test_inputs, test_outputs), tokenizer = tokenize(train_sentences,\\\n","                                                                                     train_sentences_outputs, test_sentences, test_outputs, OOV_TOKEN, NUM_WORDS)\n","\n","    if TRAINING_SIZE is not None:\n","        train_inputs, train_outputs = train_inputs[:TRAINING_SIZE, :], train_outputs[:TRAINING_SIZE, :]\n","\n","    #convert data to tf.data.Dataset\n","    dataset = train_dataset(train_inputs, train_outputs, BATCH_SIZE)\n","\n","    # clear backend\n","    tf.keras.backend.clear_session()\n","\n","    if NUM_WORDS is None:\n","        vocab_size = len(tokenizer.word_index) + 1\n","\n","    else:\n","        vocab_size = NUM_WORDS    #for word tokenizer\n","        #vocab_size = NUM_WORDS + 2    #for subword tokenier\n","\n",""],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-10T22:20:43.204304Z","iopub.execute_input":"2023-08-10T22:20:43.204696Z","iopub.status.idle":"2023-08-10T22:21:36.664176Z","shell.execute_reply.started":"2023-08-10T22:20:43.204650Z","shell.execute_reply":"2023-08-10T22:21:36.662940Z"},"trusted":true,"id":"UbCcVHeGxvQ7","outputId":"d027c899-33c9-448f-ad78-6f83317a2344"},"execution_count":null,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":["\n","learning_rate = CustomSchedule(EMBEDDING_DIM)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# initialize and compile model\n","with tpu_strategy.scope():\n","    model = Transformer(vocab_size, EMBEDDING_DIM, NUM_LAYERS, NUM_HEADS, UNITS, DROPOUT)\n","\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:21:36.670742Z","iopub.execute_input":"2023-08-10T22:21:36.671034Z","iopub.status.idle":"2023-08-10T22:21:43.599989Z","shell.execute_reply.started":"2023-08-10T22:21:36.671007Z","shell.execute_reply":"2023-08-10T22:21:43.598818Z"},"trusted":true,"id":"sMaddOnvxvQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    stop_callback = TrainingStopCallback()\n","    model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks=[stop_callback])"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-10T22:21:43.601307Z","iopub.execute_input":"2023-08-10T22:21:43.601640Z","iopub.status.idle":"2023-08-10T23:21:40.583033Z","shell.execute_reply.started":"2023-08-10T22:21:43.601611Z","shell.execute_reply":"2023-08-10T23:21:40.581663Z"},"trusted":true,"id":"pmJz7gDTxvRA","outputId":"6f1a6464-3aed-4490-d9df-92510a04d3c9"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/250\n","output_type":"stream"},{"name":"stderr","text":"2023-08-10 22:22:12.093102: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-08-10 22:22:12.877511: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"44/44 [==============================] - 111s 1s/step - loss: 2.7075 - accuracy: 0.0053\nEpoch 2/250\n44/44 [==============================] - 13s 301ms/step - loss: 2.6488 - accuracy: 0.0256\nEpoch 3/250\n44/44 [==============================] - 13s 301ms/step - loss: 2.5397 - accuracy: 0.0256\nEpoch 4/250\n44/44 [==============================] - 13s 302ms/step - loss: 2.3771 - accuracy: 0.0256\nEpoch 5/250\n44/44 [==============================] - 13s 301ms/step - loss: 2.1775 - accuracy: 0.0256\nEpoch 6/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.9650 - accuracy: 0.0256\nEpoch 7/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.7734 - accuracy: 0.0256\nEpoch 8/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.6393 - accuracy: 0.0256\nEpoch 9/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.5722 - accuracy: 0.0256\nEpoch 10/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.5466 - accuracy: 0.0256\nEpoch 11/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.5191 - accuracy: 0.0286\nEpoch 12/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.4851 - accuracy: 0.0295\nEpoch 13/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.4516 - accuracy: 0.0314\nEpoch 14/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.4179 - accuracy: 0.0347\nEpoch 15/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.3857 - accuracy: 0.0387\nEpoch 16/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.3565 - accuracy: 0.0431\nEpoch 17/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.3334 - accuracy: 0.0453\nEpoch 18/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.3128 - accuracy: 0.0470\nEpoch 19/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.2954 - accuracy: 0.0483\nEpoch 20/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.2802 - accuracy: 0.0495\nEpoch 21/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.2665 - accuracy: 0.0505\nEpoch 22/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.2530 - accuracy: 0.0514\nEpoch 23/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.2416 - accuracy: 0.0521\nEpoch 24/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.2307 - accuracy: 0.0528\nEpoch 25/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.2198 - accuracy: 0.0535\nEpoch 26/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.2100 - accuracy: 0.0541\nEpoch 27/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.2019 - accuracy: 0.0545\nEpoch 28/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1925 - accuracy: 0.0551\nEpoch 29/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1822 - accuracy: 0.0558\nEpoch 30/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1739 - accuracy: 0.0562\nEpoch 31/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1679 - accuracy: 0.0566\nEpoch 32/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1618 - accuracy: 0.0568\nEpoch 33/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1523 - accuracy: 0.0574\nEpoch 34/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1418 - accuracy: 0.0582\nEpoch 35/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1366 - accuracy: 0.0584\nEpoch 36/250\n44/44 [==============================] - 13s 304ms/step - loss: 1.1321 - accuracy: 0.0586\nEpoch 37/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1242 - accuracy: 0.0590\nEpoch 38/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1154 - accuracy: 0.0596\nEpoch 39/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.1084 - accuracy: 0.0599\nEpoch 40/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.1022 - accuracy: 0.0602\nEpoch 41/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0945 - accuracy: 0.0607\nEpoch 42/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0865 - accuracy: 0.0613\nEpoch 43/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0804 - accuracy: 0.0617\nEpoch 44/250\n44/44 [==============================] - 13s 300ms/step - loss: 1.0754 - accuracy: 0.0620\nEpoch 45/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.0687 - accuracy: 0.0625\nEpoch 46/250\n44/44 [==============================] - 13s 301ms/step - loss: 1.0611 - accuracy: 0.0630\nEpoch 47/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0539 - accuracy: 0.0636\nEpoch 48/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0487 - accuracy: 0.0639\nEpoch 49/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.0437 - accuracy: 0.0643\nEpoch 50/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.0353 - accuracy: 0.0651\nEpoch 51/250\n44/44 [==============================] - 13s 302ms/step - loss: 1.0288 - accuracy: 0.0657\nEpoch 52/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.0236 - accuracy: 0.0662\nEpoch 53/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.0171 - accuracy: 0.0668\nEpoch 54/250\n44/44 [==============================] - 13s 303ms/step - loss: 1.0071 - accuracy: 0.0679\nEpoch 55/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9960 - accuracy: 0.0690\nEpoch 56/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9902 - accuracy: 0.0696\nEpoch 57/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9877 - accuracy: 0.0697\nEpoch 58/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9827 - accuracy: 0.0703\nEpoch 59/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9765 - accuracy: 0.0709\nEpoch 60/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9695 - accuracy: 0.0717\nEpoch 61/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9643 - accuracy: 0.0722\nEpoch 62/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.9600 - accuracy: 0.0727\nEpoch 63/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9564 - accuracy: 0.0729\nEpoch 64/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9528 - accuracy: 0.0732\nEpoch 65/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9469 - accuracy: 0.0739\nEpoch 66/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.9373 - accuracy: 0.0751\nEpoch 67/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9309 - accuracy: 0.0758\nEpoch 68/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9300 - accuracy: 0.0757\nEpoch 69/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.9257 - accuracy: 0.0763\nEpoch 70/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9178 - accuracy: 0.0772\nEpoch 71/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.9105 - accuracy: 0.0782\nEpoch 72/250\n44/44 [==============================] - 13s 300ms/step - loss: 0.9042 - accuracy: 0.0790\nEpoch 73/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.9007 - accuracy: 0.0792\nEpoch 74/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.9000 - accuracy: 0.0793\nEpoch 75/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8940 - accuracy: 0.0799\nEpoch 76/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8841 - accuracy: 0.0813\nEpoch 77/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8743 - accuracy: 0.0827\nEpoch 78/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8709 - accuracy: 0.0830\nEpoch 79/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.8717 - accuracy: 0.0827\nEpoch 80/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8674 - accuracy: 0.0834\nEpoch 81/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8599 - accuracy: 0.0844\nEpoch 82/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8537 - accuracy: 0.0852\nEpoch 83/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8502 - accuracy: 0.0857\nEpoch 84/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.8461 - accuracy: 0.0860\nEpoch 85/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.8399 - accuracy: 0.0870\nEpoch 86/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8338 - accuracy: 0.0878\nEpoch 87/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8294 - accuracy: 0.0885\nEpoch 88/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.8282 - accuracy: 0.0886\nEpoch 89/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.8257 - accuracy: 0.0888\nEpoch 90/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8217 - accuracy: 0.0893\nEpoch 91/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8177 - accuracy: 0.0898\nEpoch 92/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.8135 - accuracy: 0.0904\nEpoch 93/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8104 - accuracy: 0.0908\nEpoch 94/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8069 - accuracy: 0.0913\nEpoch 95/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.8033 - accuracy: 0.0919\nEpoch 96/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7996 - accuracy: 0.0923\nEpoch 97/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.7958 - accuracy: 0.0929\nEpoch 98/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7935 - accuracy: 0.0932\nEpoch 99/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7903 - accuracy: 0.0936\nEpoch 100/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7859 - accuracy: 0.0943\nEpoch 101/250\n44/44 [==============================] - 14s 312ms/step - loss: 0.7823 - accuracy: 0.0947\nEpoch 102/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7778 - accuracy: 0.0956\nEpoch 103/250\n44/44 [==============================] - 13s 304ms/step - loss: 0.7740 - accuracy: 0.0960\nEpoch 104/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7711 - accuracy: 0.0965\nEpoch 105/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7671 - accuracy: 0.0970\nEpoch 106/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7638 - accuracy: 0.0975\nEpoch 107/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7617 - accuracy: 0.0977\nEpoch 108/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.7588 - accuracy: 0.0982\nEpoch 109/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7555 - accuracy: 0.0986\nEpoch 110/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7536 - accuracy: 0.0989\nEpoch 111/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7516 - accuracy: 0.0992\nEpoch 112/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7494 - accuracy: 0.0995\nEpoch 113/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7462 - accuracy: 0.1000\nEpoch 114/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7442 - accuracy: 0.1002\nEpoch 115/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7417 - accuracy: 0.1006\nEpoch 116/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7387 - accuracy: 0.1012\nEpoch 117/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7379 - accuracy: 0.1012\nEpoch 118/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7370 - accuracy: 0.1012\nEpoch 119/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7342 - accuracy: 0.1017\nEpoch 120/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7304 - accuracy: 0.1024\nEpoch 121/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7277 - accuracy: 0.1027\nEpoch 122/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7264 - accuracy: 0.1029\nEpoch 123/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7279 - accuracy: 0.1025\nEpoch 124/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7271 - accuracy: 0.1026\nEpoch 125/250\n44/44 [==============================] - 13s 304ms/step - loss: 0.7227 - accuracy: 0.1034\nEpoch 126/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.7187 - accuracy: 0.1041\nEpoch 127/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7151 - accuracy: 0.1047\nEpoch 128/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7106 - accuracy: 0.1055\nEpoch 129/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7077 - accuracy: 0.1060\nEpoch 130/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.7077 - accuracy: 0.1058\nEpoch 131/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.7065 - accuracy: 0.1058\nEpoch 132/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.7029 - accuracy: 0.1065\nEpoch 133/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6986 - accuracy: 0.1074\nEpoch 134/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6959 - accuracy: 0.1079\nEpoch 135/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6974 - accuracy: 0.1075\nEpoch 136/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.7003 - accuracy: 0.1068\nEpoch 137/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6977 - accuracy: 0.1072\nEpoch 138/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6920 - accuracy: 0.1083\nEpoch 139/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6889 - accuracy: 0.1088\nEpoch 140/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6879 - accuracy: 0.1090\nEpoch 141/250\n44/44 [==============================] - 13s 304ms/step - loss: 0.6895 - accuracy: 0.1085\nEpoch 142/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6911 - accuracy: 0.1081\nEpoch 143/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6872 - accuracy: 0.1088\nEpoch 144/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6817 - accuracy: 0.1099\nEpoch 145/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6771 - accuracy: 0.1107\nEpoch 146/250\n44/44 [==============================] - 13s 304ms/step - loss: 0.6738 - accuracy: 0.1114\nEpoch 147/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6739 - accuracy: 0.1112\nEpoch 148/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6767 - accuracy: 0.1104\nEpoch 149/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6771 - accuracy: 0.1102\nEpoch 150/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6730 - accuracy: 0.1111\nEpoch 151/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6683 - accuracy: 0.1121\nEpoch 152/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6632 - accuracy: 0.1130\nEpoch 153/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6602 - accuracy: 0.1135\nEpoch 154/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6612 - accuracy: 0.1132\nEpoch 155/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6645 - accuracy: 0.1125\nEpoch 156/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6669 - accuracy: 0.1119\nEpoch 157/250\n44/44 [==============================] - 13s 300ms/step - loss: 0.6631 - accuracy: 0.1126\nEpoch 158/250\n44/44 [==============================] - 13s 300ms/step - loss: 0.6581 - accuracy: 0.1136\nEpoch 159/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6530 - accuracy: 0.1147\nEpoch 160/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6487 - accuracy: 0.1155\nEpoch 161/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6484 - accuracy: 0.1155\nEpoch 162/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6509 - accuracy: 0.1148\nEpoch 163/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6554 - accuracy: 0.1138\nEpoch 164/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6556 - accuracy: 0.1136\nEpoch 165/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6515 - accuracy: 0.1146\nEpoch 166/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6457 - accuracy: 0.1158\nEpoch 167/250\n44/44 [==============================] - 13s 304ms/step - loss: 0.6409 - accuracy: 0.1168\nEpoch 168/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6373 - accuracy: 0.1173\nEpoch 169/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6359 - accuracy: 0.1176\nEpoch 170/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6410 - accuracy: 0.1164\nEpoch 171/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6459 - accuracy: 0.1153\nEpoch 172/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6454 - accuracy: 0.1154\nEpoch 173/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6430 - accuracy: 0.1159\nEpoch 174/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6375 - accuracy: 0.1170\nEpoch 175/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6327 - accuracy: 0.1180\nEpoch 176/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6287 - accuracy: 0.1188\nEpoch 177/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6258 - accuracy: 0.1193\nEpoch 178/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6267 - accuracy: 0.1190\nEpoch 179/250\n44/44 [==============================] - 13s 300ms/step - loss: 0.6303 - accuracy: 0.1182\nEpoch 180/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6316 - accuracy: 0.1178\nEpoch 181/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6314 - accuracy: 0.1177\nEpoch 182/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6315 - accuracy: 0.1176\nEpoch 183/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6294 - accuracy: 0.1181\nEpoch 184/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6247 - accuracy: 0.1191\nEpoch 185/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6204 - accuracy: 0.1200\nEpoch 186/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6165 - accuracy: 0.1207\nEpoch 187/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6157 - accuracy: 0.1209\nEpoch 188/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6174 - accuracy: 0.1204\nEpoch 189/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.6222 - accuracy: 0.1193\nEpoch 190/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6272 - accuracy: 0.1181\nEpoch 191/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6268 - accuracy: 0.1181\nEpoch 192/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6210 - accuracy: 0.1194\nEpoch 193/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6144 - accuracy: 0.1209\nEpoch 194/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6087 - accuracy: 0.1221\nEpoch 195/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6046 - accuracy: 0.1229\nEpoch 196/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6046 - accuracy: 0.1228\nEpoch 197/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6090 - accuracy: 0.1217\nEpoch 198/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6145 - accuracy: 0.1205\nEpoch 199/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6132 - accuracy: 0.1208\nEpoch 200/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6104 - accuracy: 0.1214\nEpoch 201/250\n44/44 [==============================] - 14s 313ms/step - loss: 0.6070 - accuracy: 0.1220\nEpoch 202/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6044 - accuracy: 0.1226\nEpoch 203/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6021 - accuracy: 0.1230\nEpoch 204/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6006 - accuracy: 0.1233\nEpoch 205/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6005 - accuracy: 0.1233\nEpoch 206/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.6028 - accuracy: 0.1227\nEpoch 207/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6058 - accuracy: 0.1220\nEpoch 208/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.6042 - accuracy: 0.1224\nEpoch 209/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5982 - accuracy: 0.1237\nEpoch 210/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5921 - accuracy: 0.1250\nEpoch 211/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5868 - accuracy: 0.1262\nEpoch 212/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5843 - accuracy: 0.1265\nEpoch 213/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5853 - accuracy: 0.1262\nEpoch 214/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5885 - accuracy: 0.1254\nEpoch 215/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5924 - accuracy: 0.1246\nEpoch 216/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5923 - accuracy: 0.1244\nEpoch 217/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.5916 - accuracy: 0.1246\nEpoch 218/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.5891 - accuracy: 0.1252\nEpoch 219/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5866 - accuracy: 0.1257\nEpoch 220/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5841 - accuracy: 0.1262\nEpoch 221/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5834 - accuracy: 0.1263\nEpoch 222/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5830 - accuracy: 0.1264\nEpoch 223/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5845 - accuracy: 0.1260\nEpoch 224/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5858 - accuracy: 0.1258\nEpoch 225/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5858 - accuracy: 0.1257\nEpoch 226/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5840 - accuracy: 0.1260\nEpoch 227/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5814 - accuracy: 0.1265\nEpoch 228/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5787 - accuracy: 0.1272\nEpoch 229/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5767 - accuracy: 0.1275\nEpoch 230/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5753 - accuracy: 0.1278\nEpoch 231/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5752 - accuracy: 0.1277\nEpoch 232/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5778 - accuracy: 0.1270\nEpoch 233/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5802 - accuracy: 0.1266\nEpoch 234/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5797 - accuracy: 0.1266\nEpoch 235/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5767 - accuracy: 0.1273\nEpoch 236/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5729 - accuracy: 0.1282\nEpoch 237/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5690 - accuracy: 0.1290\nEpoch 238/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5660 - accuracy: 0.1296\nEpoch 239/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5630 - accuracy: 0.1301\nEpoch 240/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5610 - accuracy: 0.1306\nEpoch 241/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5608 - accuracy: 0.1305\nEpoch 242/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5644 - accuracy: 0.1296\nEpoch 243/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5695 - accuracy: 0.1285\nEpoch 244/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5715 - accuracy: 0.1280\nEpoch 245/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5700 - accuracy: 0.1284\nEpoch 246/250\n44/44 [==============================] - 13s 301ms/step - loss: 0.5672 - accuracy: 0.1291\nEpoch 247/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5648 - accuracy: 0.1296\nEpoch 248/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5627 - accuracy: 0.1299\nEpoch 249/250\n44/44 [==============================] - 13s 303ms/step - loss: 0.5607 - accuracy: 0.1304\nEpoch 250/250\n44/44 [==============================] - 13s 302ms/step - loss: 0.5612 - accuracy: 0.1302\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7d86801de160>"},"metadata":{}}]},{"cell_type":"code","source":["    test_sentences_list = []\n","    gt_list = []\n","    for sent in train_sentences:\n","        word_list = sent.split(\" \")\n","        test_sentences_list.append(\" \".join(word_list[1:-1]))\n","\n","    for sent in train_sentences_outputs:\n","        word_list = sent.split(\" \")\n","        gt_list.append(\" \".join(word_list[1:-1]))\n","\n","    prediction(train_inputs[:50,:], test_sentences_list[:50], tokenizer, tokenizer.word_index[START_TOKEN], tokenizer.word_index[END_TOKEN], model, gt_list[:50])"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:27:59.340879Z","iopub.execute_input":"2023-08-10T23:27:59.341316Z","iopub.status.idle":"2023-08-10T23:36:42.448310Z","shell.execute_reply.started":"2023-08-10T23:27:59.341282Z","shell.execute_reply":"2023-08-10T23:36:42.446916Z"},"trusted":true,"id":"7u4LH99pxvRB","outputId":"e2f61638-23fb-4856-9e6b-3d0167cd42c9"},"execution_count":null,"outputs":[{"name":"stdout","text":"User: i am here .\nChatbot: you are not going to be late\nUser: are you okay ?\nChatbot: i am not sure i am just\nUser: i do not know , i just got i got very dizzy . . . i feel dizzy , max .\nChatbot: well i am glad to see you\nUser: why yes , thank you .\nChatbot: i am not hungry\nUser: hand it over . basic plot ?\nChatbot: i am not quite reacting to what i am council\nUser: see , i told you !\nChatbot: i am not sure i am not\nUser: we are going over to her place to make salad and pasta . just , you know , nothing special .\nChatbot: okay okay\nUser: him . . . ?\nChatbot: yes\nUser: you almost married recently , did not you ?\nChatbot: i am feeling very happy since i was twelve\nUser: i beat the odds !\nChatbot: you gonna shoot him\nUser: you are a man of the world , fettes , you would not hold me to promise given in drink .\nChatbot: i would not speak to you mrs lampert\nUser: she is got a hidden pitbull . maybe she hired someone to kill them .\nChatbot: she is not getting any minds she is not her fault\nUser: sweetheart , you are okay . you are okay . you are okay .\nChatbot: i am fine\nUser: skip , you know that it is improper completely unethical for a licensed psychologist to carry on a romantic relationship with one of his patients ?\nChatbot: i guess i do\nUser: i mean , you tie up our kid and you lock the fucking door ? are . . .\nChatbot: bobby\nUser: you speak english !\nChatbot: i do not know\nUser: you are not gonna break him with a , bet .\nChatbot: i am not sure\nUser: get out of here !\nChatbot: i am not going to let you go\nUser: that would be even worse it would be a compromise .\nChatbot: success bloom bloom bloom bloom bloom bloom bloom bloom bloom or the best of this\nUser: yeah , well , i think i will stick with what i have got .\nChatbot: you are not going to be here\nUser: uh , sue . . . ? i u cannot u .\nChatbot: you are not going to be here\nUser: yes , sir !\nChatbot: i am sorry i am not sure i am\nUser: if this is just the dump site , where did he do the job ? where did he pick her up ?\nChatbot: i do not know\nUser: depends on the varietal . just get a sense of it . thick ? thin ? watery ? syrupy ? inky ? amber , whatever . . .\nChatbot: huh\nUser: shutup ! and do not think i have not noticed how you have changed . i used to think you were a swell guy well , to be honest i thought you were an imbecile\nChatbot: aim\nUser: why me , mrs de moraes ? why should such well connected people as you hire a small time french detective to look for their missing son , mrs de moraes ?\nChatbot: who s this\nUser: i can go to the police . i have blood samples back at the hospital . i can show them .\nChatbot: you are not going to be near you yet\nUser: yes with all that pressure , and suction within\nChatbot: it is not the air force\nUser: excuse me ?\nChatbot: i am not sure i am not\nUser: you alright ?\nChatbot: yeah\nUser: thank you .\nChatbot: i am sorry i am not sure i am i am sorry i am not going to be very busy non gig\nUser: now will you go ?\nChatbot: i do not want to be alone\nUser: the first rule of project\nChatbot: right\nUser: but it is impossible .\nChatbot: i do not know\nUser: please . . .\nChatbot: i am not going to be here\nUser: this pensacola teeny bopper jail bait but built ? ten bucks she wanted . three of us made a deal for , twenty five , see , big goddam bargain ?\nChatbot: big peni goddam cillin bargain right\nUser: have no fear . this shoshone medicine woman taught me how to make bug repellent tea out of tree root .\nChatbot: you drink bug repellent\nUser: you had better manners as a pig .\nChatbot: i am not deaf y know\nUser: say , brad . i think he will be better off doing it his way .\nChatbot: he is a friend of mine\nUser: yeah .\nChatbot: i am sorry\nUser: i put him to work .\nChatbot: i am sorry\nUser: fire is like a living thing . wild . unpredictable .\nChatbot: what is it\nUser: if we do not escape , we gotta get the word out about the cash . that is how we will stay alive .\nChatbot: i am sorry\nUser: uh huh .\nChatbot: i am not sure i am not\nUser: like i had to say it ? no , i wanted to say it .\nChatbot: you are not going to be here\nUser: well . . . thank you . but . . . you know you are not supposed to be within four hundred yards of me .\nChatbot: i am not going to let you go to the office and get your job and get it to me\nUser: right , sure thing . but what about , like , appliances ? like a little color portable ? boom box ?\nChatbot: useless distractions\nUser: sir , we wont be able to bring you back . its a one way trip . captain , i do not know if the transporter . . .\nChatbot: it is not the air force\nUser: really ?\nChatbot: i am sorry i am not sure i am\nUser: yeah .\nChatbot: i am sorry\n0.026972743212316644\n","output_type":"stream"}]},{"cell_type":"code","source":["    test_input_sentences = [\"Hello, what's up?\", \"What is your plan?\", \"Are you going to the gym now?\", \"When is the book due\", \"What's the point?\", \"I'm visiting my parents tomorrow\", \"It'll be windy next week\"]\n","    test_inputs = preprocess_testdata(test_input_sentences, tokenizer, START_TOKEN, END_TOKEN)\n","    prediction(test_inputs, test_input_sentences, tokenizer, tokenizer.word_index[START_TOKEN], tokenizer.word_index[END_TOKEN], model)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:39:50.734873Z","iopub.execute_input":"2023-08-10T23:39:50.735976Z","iopub.status.idle":"2023-08-10T23:40:13.624610Z","shell.execute_reply.started":"2023-08-10T23:39:50.735929Z","shell.execute_reply":"2023-08-10T23:40:13.623291Z"},"trusted":true,"id":"vWlB9yvpxvRC","outputId":"afc0285f-71a7-454d-eca1-0ae588586736"},"execution_count":null,"outputs":[{"name":"stdout","text":"User: Hello, what's up?\nChatbot: i am not sure i am sorry\nUser: What is your plan?\nChatbot: i am not going to let this team get em\nUser: Are you going to the gym now?\nChatbot: right\nUser: When is the book due\nChatbot: uh uh we are going to seal it\nUser: What's the point?\nChatbot: i am not sure i am not going to be a good night\nUser: I'm visiting my parents tomorrow\nChatbot: immediately\nUser: It'll be windy next week\nChatbot: i know focusing\n","output_type":"stream"}]}]}